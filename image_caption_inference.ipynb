{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "e4BdgGfH718Y",
    "outputId": "c445b433-4540-4089-d064-759d214b57dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "#set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#accessing files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#display charts/images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#don't need\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "# from tensorflow.python.keras.preprocessing import text\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9__sYCZ7718e"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'image_size': [299, 299],\n",
    "    'text_input': (58,),\n",
    "    'batch_size': 512,\n",
    "    'vocab_size': 30000,\n",
    "    'examples_per_file': 850, #will not change\n",
    "    'test_examples_per_file': 500,\n",
    "    'version': 10, #model version number\n",
    "    'caption_text_input_length': 49,\n",
    "    'caption_model_version': 4,\n",
    "    'meme_text_length': 58,\n",
    "    'caption_embedding_dim': 300,\n",
    "    'caption_vocab_size' : 10000,\n",
    "    'tokenizer_start_index': 58, #index of tokenizer to signal sequence start\n",
    "    'tokenizer_end_index': 57,\n",
    "\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g3ZOLb6A718k"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    credentials=None\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RtWVR2pi7KVR"
   },
   "outputs": [],
   "source": [
    "def get_list_files_from_bucket(client_, bucket_,\n",
    "                              prefix_='hatefulmemes_'):\n",
    "    '''\n",
    "    gets list of files from bucket with predefined prefix\n",
    "    \n",
    "    args:\n",
    "        client_: google.cloud.storage.Client object\n",
    "        bucket_: str, name of bucket\n",
    "        prefix_: str, default 'hatefulmemes_' prefix of file names\n",
    "    returns:\n",
    "        paths to files in bucket with above prefix\n",
    "    '''\n",
    "    objects = client_.list_blobs(bucket_, prefix=prefix_)\n",
    "    files = []\n",
    "    for object_ in objects:\n",
    "        path = str(object_).split(', ')[1]\n",
    "        gs_path = os.path.join('gs://', bucket_, path)\n",
    "        files.append(gs_path)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "BMUqKpKY718s"
   },
   "outputs": [],
   "source": [
    "tfrecords = get_list_files_from_bucket(client,\n",
    "                                      bucket_='jh_hateful_memes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CogGhHQB718u"
   },
   "outputs": [],
   "source": [
    "# tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "VdrBIeYx718x",
    "outputId": "e4b6baec-eff9-4599-b285-2766692db3d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rm40cYA_718y"
   },
   "outputs": [],
   "source": [
    "def decode_example_train(example):\n",
    "    '''\n",
    "    decodes single tfexample from TFrecord file\n",
    "    '''\n",
    "    features = {'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma_no_stopwords': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_no_stopwords':tf.io.FixedLenFeature([], tf.string),\n",
    "                'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "    single_example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    text = tf.io.parse_tensor(single_example['text'], out_type=tf.int32)\n",
    "    textL = tf.io.parse_tensor(single_example['text_lemma'], out_type=tf.int32)\n",
    "    # text = tf.cast(text, tf.float32) \n",
    "    image = tf.io.decode_jpeg(single_example['image'], 3)\n",
    "    image = tf.image.resize_with_pad(image, *params['image_size'])\n",
    "    image = image / 127.5\n",
    "    image = image -1\n",
    "    label = single_example['label']\n",
    "    # label = tf.cast(label, tf.float32)\n",
    "    return text, image, label\n",
    "\n",
    "def decode_example_test(example):\n",
    "    '''\n",
    "    decodes single tfexample from TFrecord file\n",
    "    '''\n",
    "    features = {'id': tf.io.FixedLenFeature([], tf.int64),\n",
    "                'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma_no_stopwords': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_no_stopwords':tf.io.FixedLenFeature([], tf.string),\n",
    "                'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "    single_example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    text = tf.io.parse_tensor(single_example['text'], out_type=tf.int32)\n",
    "    textL = tf.io.parse_tensor(single_example['text_lemma'], out_type=tf.int32)\n",
    "    # text = tf.cast(text, tf.float32) \n",
    "    image = tf.io.decode_jpeg(single_example['image'], 3)\n",
    "    image = tf.image.resize_with_pad(image, *params['image_size'])\n",
    "    image = image / 127.5\n",
    "    image = image -1\n",
    "    label = single_example['id']\n",
    "    # label = tf.cast(label, tf.float32)\n",
    "    return text, image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PZ0dHSjt7180"
   },
   "outputs": [],
   "source": [
    "def create_ds(files, params, train=True, test_examples=1000):\n",
    "    '''\n",
    "    function to create dataset for training/validation\n",
    "    \n",
    "    args:\n",
    "        files: list of str, filepaths of TFrecord files to be used in DS\n",
    "        params: dict with the following keys:\n",
    "            batch_size: int, batch size of training/validation step\n",
    "            examples_per_file: int, number of examples in each TFrecord file\n",
    "        train, bool, default True, indicator if the DS is for training\n",
    "        test_examples, int: default 1000 number of examples in test dataset\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images, text and labels\n",
    "            output of ds is: (text, image), label\n",
    "        ds_batches: int, number of steps in each epoch based on the batch_size\n",
    "    '''\n",
    "    file_size = params['examples_per_file'] \n",
    "    batch_size = file_size * len(files)\n",
    "\n",
    "    ds = tf.data.TFRecordDataset(filenames = files)\n",
    "    if train:\n",
    "        ds = ds.map(decode_example_train, \n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    else:\n",
    "        ds = ds.map(decode_example_test)\n",
    "    if train:\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.batch(test_examples)\n",
    "    \n",
    "    ds_batches = 10 #(len(files) * file_size) // batch_size\n",
    "    return ds, ds_batches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pG08Jw4NRl5O"
   },
   "outputs": [],
   "source": [
    "def download_file(client, bucket, file_name):\n",
    "    '''\n",
    "    downloads a file from a GCS bucket into working directory\n",
    "\n",
    "    args:\n",
    "        client: google.cloud.storage.Client object\n",
    "        bucket: str, name of bucket to download file from\n",
    "        file_name: str, file name to download\n",
    "    returns: None\n",
    "    \n",
    "    '''\n",
    "    _bucket = client.bucket(bucket)\n",
    "    blob = _bucket.blob(file_name)\n",
    "    blob.download_to_filename(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6O0X87clZr8j"
   },
   "outputs": [],
   "source": [
    "def get_caption_model(params, client, bucket):\n",
    "    '''\n",
    "    creates pretrained image caption model, and inception model less last layer\n",
    "    '''\n",
    "    \n",
    "    model_num = params['caption_model_version']\n",
    "    model_path = 'image_caption_model_v{}.h5'.format(model_num)\n",
    "    if not os.path.isfile(model_path):\n",
    "        download_file(client, bucket,model_path)\n",
    "    \n",
    "    \n",
    "    caption_model = tf.keras.models.load_model(model_path)\n",
    "    \n",
    "    model = tf.keras.applications.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "    inp = model.input\n",
    "    out = model.layers[-2].output\n",
    "    mdl = tf.keras.Model(inp, out)\n",
    "\n",
    "    return caption_model, mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "gWaYlXqzRl5X"
   },
   "outputs": [],
   "source": [
    "def get_image_captions(params, images, image_texts):\n",
    "    '''\n",
    "    creates captions to a group of images\n",
    "    \n",
    "    args:\n",
    "        params: dictionary with at least the following keys:\n",
    "            caption_text_input_length: int, length of captions\n",
    "            tokenizer_start_index: int, value to signal start of caption\n",
    "            tokenizer_end_index: int, value to signal end of caption\n",
    "            \n",
    "        images: tensor, dtype: tf.float32 shaped (None, 299, 299, 3) None is the \n",
    "        number of images, each image should be normalized to have\n",
    "        pixel values of -1 to 1. Images to be captioned\n",
    "        image_texts, tensor, dtype: tf.int32, shaped (None, 1, NONE) None is the \n",
    "        number of images, and NONE is an arbitrary number. Text of each image\n",
    "\n",
    "            \n",
    "    returns:\n",
    "        captions: list of lists, dtype float, shaped \n",
    "        (None, params['caption_text_input_length'])None is the number of \n",
    "        images, image caption sequences\n",
    "        texts: list of lists, shaped same as captions, image text sequences\n",
    "    '''\n",
    "    num_images = len(images)\n",
    "    caption_len = params['caption_text_input_length']\n",
    "    caption_end_index = params['tokenizer_end_index']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    captions = list()\n",
    "    texts = list()\n",
    "    for image in range(num_images):\n",
    "        img_ = images[image]\n",
    "        img_ = tf.expand_dims(img_, axis=0)\n",
    "        img = get_image_features(img_)\n",
    "        \n",
    "        txt_input = np.zeros((caption_len))\n",
    "        result = params['tokenizer_start_index']\n",
    "        for idx in range(caption_len):\n",
    "            txt_input[idx] = result\n",
    "            result = get_capt(img, txt_input)\n",
    "            result = result.numpy()[0] #.values[0]\n",
    "            if result == caption_end_index:\n",
    "                break\n",
    "        txt_input_ = txt_input.tolist()\n",
    "        captions.append(txt_input_)\n",
    "        text = image_texts[image].numpy().tolist()\n",
    "        texts.append(text)\n",
    "    return captions, texts \n",
    "\n",
    "@tf.function\n",
    "def get_image_features(image):\n",
    "    def features(img):\n",
    "        pred = feature_model(img)\n",
    "        return pred\n",
    "    result = strategy.run(features, args=(image,))\n",
    "    return result\n",
    "        \n",
    "@tf.function\n",
    "def get_capt(img, txt):\n",
    "    def caption_step(image_, text_):\n",
    "        '''\n",
    "        evaluate model here\n",
    "        '''\n",
    "        txt_ = tf.expand_dims(text_, axis=0)\n",
    "        pred = caption_model((image_, txt_))\n",
    "        pred_ = tf.argmax(pred, axis=-1, name='model_prediction')\n",
    "\n",
    "\n",
    "        return pred_\n",
    "    result = strategy.run(caption_step, args=(img, txt))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "alJt8bQV7185"
   },
   "outputs": [],
   "source": [
    "dataset, _ = create_ds(tfrecords, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "S25BV5he7187",
    "outputId": "dcedb4ce-e265-4cdd-84ac-0ba40597652a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "with strategy.scope():\n",
    "\n",
    "    caption_model, feature_model = get_caption_model(params, client, 'jh_hateful_memes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dbYqcMyy718-"
   },
   "outputs": [],
   "source": [
    "for text, image, label in dataset:\n",
    "#     texts = text\n",
    "    labels = label\n",
    "    image_captions, texts = get_image_captions(params, image, text)\n",
    "    \n",
    "    break\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "aoqLCwl49-X_"
   },
   "outputs": [],
   "source": [
    "def upload_inference_csv(params, text_list, img_caption_list, label_list,\n",
    "                        bucket_, client, prefix):\n",
    "    '''\n",
    "    function to upload image captions, meme texts, and labels as CSV files \n",
    "    to a bucket\n",
    "    args:\n",
    "        params, dictionary with the following key:\n",
    "            caption_model_version: int, image caption version number\n",
    "        text_list: array of meme text sequences\n",
    "        img_caption_list: array of image caption sequences\n",
    "        label_list: list, image labels\n",
    "        bucket_: str, bucket to uplaod CSV files to\n",
    "        client: google.cloud.storage.Client object\n",
    "        prefix: str, prefix to append to the beginng of each file name\n",
    "    \n",
    "    returns: None\n",
    "    '''\n",
    "    caption_version = params['caption_model_version']\n",
    "    text_df = pd.DataFrame(text_list)\n",
    "    text_file = '{}_caption_model_text_v{}.csv'.format(prefix, caption_version)\n",
    "    text_df.to_csv(text_file, index=False)\n",
    "    caption_df = pd.DataFrame(img_caption_list)\n",
    "    caption_file = '{}_caption_model_captions_v{}.csv'.format(prefix, caption_version)\n",
    "    caption_df.to_csv(caption_file, index=False)\n",
    "    label_df = pd.DataFrame(label_list)\n",
    "    label_file = '{}_caption_model_label_v{}.csv'.format(prefix, caption_version)\n",
    "    label_df.to_csv(label_file, index=False)\n",
    "    _bucket = client.bucket(bucket_)\n",
    "    for file in [text_file, caption_file, label_file]:\n",
    "        blob = _bucket.blob(file)\n",
    "        blob.upload_from_filename(file)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kpeE2kpM9-YE"
   },
   "outputs": [],
   "source": [
    "upload_inference_csv(params, texts, image_captions, labels,\n",
    "                    'jh_hateful_memes', client, 'training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Dh9c21R6lEZc"
   },
   "outputs": [],
   "source": [
    "tfrecords = get_list_files_from_bucket(client, \n",
    "                                       bucket_='jh_hateful_memes_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "bcVbjWe8i-Kr"
   },
   "outputs": [],
   "source": [
    "test_ds, test_steps = create_ds(tfrecords, params, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "or7-zGBVlppw"
   },
   "outputs": [],
   "source": [
    "for text, image, label in test_ds:\n",
    "    # texts = text\n",
    "    labels = label\n",
    "    image_captions, texts = get_image_captions(params, image, text)\n",
    "    \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ABcoxiAH_le8"
   },
   "outputs": [],
   "source": [
    "upload_inference_csv(params, texts, image_captions, labels,\n",
    "                    'jh_hateful_memes', client, 'test_seen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "xO8Zzf48n5X1"
   },
   "outputs": [],
   "source": [
    "tfrecords = get_list_files_from_bucket(client, \n",
    "                                       bucket_='jh_hateful_memes_test_unseen')\n",
    "test_ds_unseen, _ = create_ds(tfrecords, params, train=False)\n",
    "\n",
    "for text, image, label in test_ds_unseen:\n",
    "    # texts = text\n",
    "    labels = label\n",
    "    image_captions, texts = get_image_captions(params, image, text)\n",
    "    \n",
    "    break\n",
    "\n",
    "upload_inference_csv(params, texts, image_captions, labels,\n",
    "                    'jh_hateful_memes', client, 'test_unseen')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "73p7c5BY7V66"
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "WoQD_1fB7aGY",
    "outputId": "f8493535-8c4c-4df8-ae37-61863af7a157"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'{\\n  \"ip\": \"104.198.217.94\",\\n  \"hostname\": \"94.217.198.104.bc.googleusercontent.com\",\\n  \"city\": \"Council Bluffs\",\\n  \"region\": \"Iowa\",\\n  \"country\": \"US\",\\n  \"loc\": \"41.2619,-95.8608\",\\n  \"org\": \"AS15169 Google LLC\",\\n  \"postal\": \"51502\",\\n  \"timezone\": \"America/Chicago\",\\n  \"readme\": \"https://ipinfo.io/missingauth\"\\n}'"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'http://ipinfo.io/json'\n",
    "response = requests.get(url)\n",
    "response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o5jv4TR37cZR"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "image_caption_inference (2).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
