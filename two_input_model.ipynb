{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#accessing files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#display charts/images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#don't need\n",
    "# from tensorflow.python.keras.preprocessing import sequence\n",
    "# from tensorflow.python.keras.preprocessing import text\n",
    "# import tensorflow_hub as hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    credentials=None\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "    client = storage.Client(project='hateful-memes', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_per_tfrecordfile = 850 #this will not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'jh_hateful_memes_dev'\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n",
    "objects = client.list_blobs(bucket, prefix='hatefulmemes_')\n",
    "tfrecords = []\n",
    "for object_ in objects:\n",
    "    path = str(object_).split(', ')[1]\n",
    "    gs_path = os.path.join('gs://', bucket, path)\n",
    "    tfrecords.append(path) #gs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    features = {'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma_no_stopwords': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_no_stopwords':tf.io.FixedLenFeature([], tf.string),\n",
    "                'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "    img = tf.io.parse_single_example(img, features)\n",
    "\n",
    "    text = tf.io.parse_tensor(img['text'], out_type=tf.int32)\n",
    "    image = tf.io.decode_jpeg(img['image'], 3)\n",
    "    image = tf.image.resize_with_pad(image, 225, 225)\n",
    "    image = image / 255.0\n",
    "    label = img['label']\n",
    "    return (text, image), label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_ds(files, batch_size, tpu=tpu):\n",
    "    '''\n",
    "    function to create dataset\n",
    "    \n",
    "    args:\n",
    "        files: list of str, filepaths of TFrecord files to be used in DS\n",
    "        batch_size: int, batch size of training/validation step\n",
    "        tpu: bool, default 'tpu' global variable, True is TPU is being used\n",
    "    \n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images, text and labels\n",
    "        if tpu is True, output of ds is: text, image, label\n",
    "        if tpu is False, output of ds is: (text, image), label\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.TFRecordDataset(filenames = [tfrecords]).map(preprocess).batch(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    '''\n",
    "    creates model with two inputs and out output\n",
    "    '''\n",
    "    input_text = layers.Input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo - make into function\n",
    "input_text = layers.Input((58,))\n",
    "embedding = layers.Embedding(input_dim=30000, output_dim=64, input_length=58, mask_zero=True)(input_text)\n",
    "x_text = embedding\n",
    "x_text = layers.SeparableConv1D(filters=64, kernel_size=4, activation='relu', padding='same')(x_text)\n",
    "x_text = layers.SeparableConv1D(filters=64, kernel_size=4, activation='relu', padding='same')(x_text)\n",
    "x_text = layers.MaxPooling1D(4, padding='same')(x_text)\n",
    "x_text = layers.SeparableConv1D(filters=64, kernel_size=4, activation='relu', padding='same')(x_text)\n",
    "x_text = layers.SeparableConv1D(filters=64, kernel_size=4, activation='relu', padding='same')(x_text)\n",
    "x_text = layers.MaxPooling1D(4, padding='same')(x_text)\n",
    "x_text = layers.Flatten()(x_text)\n",
    "output_layer_text = layers.Dense(4, activation='sigmoid')(x_text)\n",
    "\n",
    "input_image = layers.Input((225, 225, 3))#todo -make the 225 call a variable\n",
    "x_img = input_image\n",
    "x_img = layers.Conv2D(filters=64, kernel_size=5, padding='same')(x_img)\n",
    "x_img = layers.MaxPooling2D(2, 2)(x_img)\n",
    "x_img = layers.BatchNormalization()(x_img)\n",
    "x_img = layers.ReLU()(x_img)\n",
    "x_img = layers.Dense(16, activation='tanh')(x_img)\n",
    "x_img = layers.Conv2D(filters=128, kernel_size=5, padding='same')(x_img)\n",
    "x_img = layers.MaxPooling2D(2, 2)(x_img)\n",
    "x_img = layers.BatchNormalization()(x_img)\n",
    "x_img = layers.ReLU()(x_img)\n",
    "x_img = layers.Dense(16, activation='tanh')(x_img)\n",
    "x_img = layers.Flatten()(x_img)\n",
    "output_layer_image = layers.Dense(4, activation='sigmoid')(x_img)\n",
    "\n",
    "x = layers.Concatenate()([output_layer_text, output_layer_image])\n",
    "x = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "model = keras.Model([input_text, input_image], x)\n",
    "model.summary()\n",
    "metrics = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "]\n",
    "model.compile(\n",
    "optimizer=tf.keras.optimizers.Adam(0.0003),\n",
    "loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(ds, epochs=4, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
