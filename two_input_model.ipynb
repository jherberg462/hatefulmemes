{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e4BdgGfH718Y",
    "outputId": "c0380255-7ecf-4cb9-9b31-b1362844f4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "#set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#accessing files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#display charts/images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#don't need\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "# from tensorflow.python.keras.preprocessing import text\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import json\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9__sYCZ7718e"
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'image_size': [299, 299],\n",
    "    'text_input': (58,),\n",
    "    'batch_size': 512,\n",
    "    'vocab_size': 30000,\n",
    "    'examples_per_file': 850, #will not change\n",
    "    'test_examples_per_file': 500,\n",
    "    'version': 10, #model version number\n",
    "    #get this from the model zoo:\n",
    "    #https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "    'object_detection_url': 'http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz',\n",
    "    'object_det_thres' : 0.4,\n",
    "    'object_det_len': 15,\n",
    "    'caption_text_input_length': 49,\n",
    "    'caption_model_version': 2,\n",
    "    'meme_text_length': 58,\n",
    "    'caption_embedding_dim': 300,\n",
    "    'caption_vocab_size' : 10000,\n",
    "    'tokenizer_start_index': 58, #index of tokenizer to signal sequence start\n",
    "    'tokenizer_end_index': 57,\n",
    "\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3ZOLb6A718k"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    credentials=None\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3cjmD1w-718p"
   },
   "outputs": [],
   "source": [
    "num_examples_per_tfrecordfile = params['examples_per_file'] # 850 #this will not change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMUqKpKY718s"
   },
   "outputs": [],
   "source": [
    "bucket = 'jh_hateful_memes'\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n",
    "objects = client.list_blobs(bucket, prefix='hatefulmemes_')\n",
    "tfrecords = []\n",
    "for object_ in objects:\n",
    "    path = str(object_).split(', ')[1]\n",
    "    gs_path = os.path.join('gs://', bucket, path)\n",
    "    tfrecords.append(gs_path) #gs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CogGhHQB718u"
   },
   "outputs": [],
   "source": [
    "# tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "colab_type": "code",
    "id": "VdrBIeYx718x",
    "outputId": "08a34c72-ba9a-481d-fba2-d770ea5eb091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.81.89.242:8470\n",
      "INFO:tensorflow:Initializing the TPU system: grpc://10.81.89.242:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.81.89.242:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rm40cYA_718y"
   },
   "outputs": [],
   "source": [
    "def decode_example_train(example):\n",
    "    '''\n",
    "    decodes single tfexample from TFrecord file\n",
    "    '''\n",
    "    features = {'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "                'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma_no_stopwords': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_no_stopwords':tf.io.FixedLenFeature([], tf.string),\n",
    "                'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "    single_example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    text = tf.io.parse_tensor(single_example['text'], out_type=tf.int32)\n",
    "    textL = tf.io.parse_tensor(single_example['text_lemma'], out_type=tf.int32)\n",
    "    # text = tf.cast(text, tf.float32) \n",
    "    image = tf.io.decode_jpeg(single_example['image'], 3)\n",
    "    image = tf.image.resize_with_pad(image, *params['image_size'])\n",
    "    image = image / 127.5\n",
    "    image = image -1\n",
    "    label = single_example['label']\n",
    "    # label = tf.cast(label, tf.float32)\n",
    "    return text, image, label\n",
    "\n",
    "def decode_example_test(example):\n",
    "    '''\n",
    "    decodes single tfexample from TFrecord file\n",
    "    '''\n",
    "    features = {'id': tf.io.FixedLenFeature([], tf.int64),\n",
    "                'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_lemma_no_stopwords': tf.io.FixedLenFeature([], tf.string),\n",
    "                'text_no_stopwords':tf.io.FixedLenFeature([], tf.string),\n",
    "                'image': tf.io.FixedLenFeature([], tf.string)}\n",
    "    single_example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    text = tf.io.parse_tensor(single_example['text'], out_type=tf.int32)\n",
    "    textL = tf.io.parse_tensor(single_example['text_lemma'], out_type=tf.int32)\n",
    "    # text = tf.cast(text, tf.float32) \n",
    "    image = tf.io.decode_jpeg(single_example['image'], 3)\n",
    "    image = tf.image.resize_with_pad(image, *params['image_size'])\n",
    "    image = image / 127.5\n",
    "    image = image -1\n",
    "    label = single_example['id']\n",
    "    # label = tf.cast(label, tf.float32)\n",
    "    return text, image, label\n",
    "\n",
    "def flip_image(text, image, label): \n",
    "    '''\n",
    "    randombly flips image input\n",
    "    \n",
    "    args:\n",
    "        text: text output in ds\n",
    "        image: image output in ds\n",
    "        label: label output in ds (can also be id)\n",
    "    returns:\n",
    "        text, image, label\n",
    "        args will be otherwise unchanged\n",
    "    '''\n",
    "    \n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "\n",
    "    return text, image, label\n",
    "\n",
    "\n",
    "def convert_xy(text, image, label): #needs to be called last\n",
    "    '''\n",
    "    transforms ds output from text, image, label -> (text, image), label\n",
    "    \n",
    "    args:\n",
    "        text: text output in ds\n",
    "        image: image output in ds\n",
    "        label: label output in ds (can also be id)\n",
    "    returns:\n",
    "        (text, image), label\n",
    "        args will be otherwise unchanged\n",
    "    '''\n",
    "    return (text, image), label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZ0dHSjt7180"
   },
   "outputs": [],
   "source": [
    "def create_ds(files, params, train=True, test_examples=1000):\n",
    "    '''\n",
    "    function to create dataset for training/validation\n",
    "    \n",
    "    args:\n",
    "        files: list of str, filepaths of TFrecord files to be used in DS\n",
    "        params: dict with the following keys:\n",
    "            batch_size: int, batch size of training/validation step\n",
    "            examples_per_file: int, number of examples in each TFrecord file\n",
    "        train, bool, default True, indicator if the DS is for training\n",
    "        test_examples, int: default 1000 number of examples in test dataset\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images, text and labels\n",
    "            output of ds is: (text, image), label\n",
    "        ds_batches: int, number of steps in each epoch based on the batch_size\n",
    "    '''\n",
    "    file_size = params['examples_per_file'] \n",
    "    batch_size = file_size * len(files)\n",
    "\n",
    "    ds = tf.data.TFRecordDataset(filenames = files)\n",
    "    if train:\n",
    "        ds = ds.map(decode_example_train, \n",
    "                    num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "        ds = ds.map(flip_image, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    else:\n",
    "        ds = ds.map(decode_example_test)\n",
    "    ds = ds.map(convert_xy, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    if train:\n",
    "        ds = ds.batch(batch_size, drop_remainder=True)\n",
    "    else:\n",
    "        ds = ds.batch(test_examples)\n",
    "    ds = ds.cache() \n",
    "    \n",
    "    ds_batches = 10 #(len(files) * file_size) // batch_size\n",
    "    return ds, ds_batches\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pG08Jw4NRl5O"
   },
   "outputs": [],
   "source": [
    "def download_file(client, bucket, file_name):\n",
    "    '''\n",
    "    downloads a file from a GCS bucket into working directory\n",
    "\n",
    "    args:\n",
    "        client: google.cloud.storage.Client object\n",
    "        bucket: str, name of bucket to download file from\n",
    "        file_name: str, file name to download\n",
    "    returns: None\n",
    "    \n",
    "    '''\n",
    "    _bucket = client.bucket(bucket)\n",
    "    blob = _bucket.blob(file_name)\n",
    "    blob.download_to_filename(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMCXQxNEMMx0"
   },
   "outputs": [],
   "source": [
    "def get_object_detection_model(params):\n",
    "    '''\n",
    "    downloads pretained object detection model from tf zoo \n",
    "    and creates model instance\n",
    "    \n",
    "    args:\n",
    "        params: dict with the following keys:\n",
    "            object_detection_url: str, url of model in model zoo:\n",
    "    (https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)\n",
    "    \n",
    "    returns:\n",
    "        pretrained object detection model\n",
    "    '''\n",
    "    url = params['object_detection_url']\n",
    "    model_name = url.split('.tar.')[0].split('/')[-1]\n",
    "    local_model_location = tf.keras.utils.get_file(fname=model_name,\n",
    "                                                  origin=url,\n",
    "                                                  untar=True)\n",
    "    model_path = os.path.join(local_model_location, 'saved_model')\n",
    "    model = hub.load(model_path)\n",
    "    model = model.signatures['serving_default']\n",
    "    return model\n",
    "\n",
    "def decode_single_object_detection(predictions, idx, threshold, max_objects):\n",
    "    '''\n",
    "    decodes a single prediction of all object classes in the prediction\n",
    "    \n",
    "    args:\n",
    "        predictions: dictionary, prediction dictionary\n",
    "            must have following keys:\n",
    "            detection_classes: tensor of detection classes\n",
    "            detection_scores: tensor of confidence of each detected object\n",
    "        idx: int, the index of the predictions dictionary that is being decoded\n",
    "        threshold: float, between 0 - 1, minimum confidence of detected objects\n",
    "            to be included in list of objects detected\n",
    "        max_objects: int, maximum number of objects to be included in prediction\n",
    "            if there are less predicted objects above threshold, returned list will\n",
    "            be zero padded\n",
    "            \n",
    "    returns:\n",
    "        array of classes of objects being predicted\n",
    "    '''\n",
    "    classes = predictions['detection_classes'][idx]\n",
    "    confidences = predictions['detection_scores'][idx]\n",
    "    predicted_classes = []\n",
    "    for indx in range(len(confidences)):\n",
    "        if confidences[indx] < threshold:\n",
    "            break\n",
    "        predicted_classes.append(int(classes[indx].numpy()))\n",
    "    return sequence.pad_sequences([predicted_classes], maxlen=max_objects)[0].tolist()\n",
    "\n",
    "\n",
    "\n",
    "def make_object_detectionDS(params, images, model):\n",
    "    '''\n",
    "    converts a batch of images to a batch of predicted classes of objects\n",
    "    \n",
    "    args:\n",
    "        params: dictionary with following keys:\n",
    "            object_det_thres: float, minimum confidence of detected objects\n",
    "            to be included in list of objects detected, must be between 0 - 1\n",
    "            object_det_len: int, maximum number of objects to be included in \n",
    "            prediction if there are less predicted objects above threshold, \n",
    "            returned tensor will be zero padded\n",
    "        images tensor, batch of images to get predicted classes of objects\n",
    "            for\n",
    "        model: pre-trained object detection model\n",
    "    \n",
    "    returns: tensor shapped [bs, params['object_det_len']], output of model\n",
    "        of predicted classes each image contains, zero-padded so that each\n",
    "        image prediction has a len of params['object_det_len'], and predictions\n",
    "        under params['object_det_thres'] are filtered out\n",
    "    '''\n",
    "    thres = params['object_det_thres']\n",
    "    maxlen = params['object_det_len']\n",
    "    model_output = model(images)\n",
    "    predictions = []\n",
    "    for idx in range(len(images)):\n",
    "        single_image_output = decode_single_object_detection(model_output, idx,\n",
    "                                                            thres, maxlen)\n",
    "        predictions.append(single_image_output)\n",
    "    predictions = tf.convert_to_tensor(predictions)\n",
    "    return predictions\n",
    "\n",
    "def transform_normalized_uint8(data):\n",
    "    '''\n",
    "    transforms a tensor normalized (0 - 1) to dtype uint8\n",
    "    \n",
    "    args:\n",
    "        data: tensor, data to be transformed\n",
    "        \n",
    "    returns:\n",
    "        tensor of data in dtype of unit8 and no longer normalized\n",
    "    '''\n",
    "    data *= 255\n",
    "    data = tf.cast(data, tf.uint8)\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6RbH_oRmjUU"
   },
   "outputs": [],
   "source": [
    "def pair_separableConv1D(x, \n",
    "                         filters, kernal_size, act, first_reg, sec_reg,\n",
    "                        maxpooling_poolsize):\n",
    "    '''\n",
    "    function to add the following layers to a Keras Functional model:\n",
    "        layers.SeparableConv1D\n",
    "        layers.SeparableConv1D\n",
    "        layers.MaxPooling1D\n",
    "    \n",
    "    args:\n",
    "        x: keras input layer, or series of layers that can be traced to input layer\n",
    "        kernal_size: int, kernal size for SeparableConv1D layers\n",
    "        act: str, activation for SeparableConv1D layers\n",
    "        first_reg, keras regularizer to pass into 1st conv layer\n",
    "        sec_reg, keras regularizer to pass into 2nd conv layer\n",
    "        maxpooling_poolsize: int, poolsize for maxpooling layer\n",
    "    \n",
    "    returns:\n",
    "        x: x that was input into fn with above layers added\n",
    "    '''\n",
    "    x = layers.SeparableConv1D(filters=filters, kernel_size=kernal_size, \n",
    "                              activation=act, padding='same',\n",
    "                              kernel_regularizer=first_reg)(x)\n",
    "    x = layers.SeparableConv1D(filters=filters, kernel_size=kernal_size, \n",
    "                              activation=act, padding='same',\n",
    "                              kernel_regularizer=sec_reg)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=maxpooling_poolsize, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z7nJDhlumjUX"
   },
   "outputs": [],
   "source": [
    "def conv2dset(x, \n",
    "              conv_filter, kernel, regularizer=None, \n",
    "              maxpooling_poolsize=2, \n",
    "              conv_act=None, \n",
    "              dense_units=None, dense_act=None):\n",
    "    '''\n",
    "    function to add the following layers to a Keras Functional model:\n",
    "        layers.Conv2D\n",
    "        MaxPooling2D\n",
    "        Batchnormalization\n",
    "        (activation layer)\n",
    "        layers.Dense (if applicable)\n",
    "    \n",
    "    args:\n",
    "        x: keras input layer, or series of layers that can be traced to input layer\n",
    "        conv_filter: int, number of filters in Conv2D layer\n",
    "        kernel: int, kernel size in Conv2D layer\n",
    "        regularizer: keras.regularizers object, default: None, regularizer in \n",
    "            Conv2D layer\n",
    "        maxpooling_poolsize: int, default 2, poolsize for maxpooling layer\n",
    "        conv_act: keras layer (without the \"()\"), default None, activation\n",
    "            layer that will go after the batchnormalization layer\n",
    "        dense_units: int, default None, number of units in dense layer\n",
    "            if None, there will be no dense layer\n",
    "        dense_act: str, default None, activation in dense layer\n",
    "    \n",
    "    returns:\n",
    "        x: x that was input into fn with above layers added\n",
    "        \n",
    "    '''\n",
    "    x = layers.Conv2D(filters=conv_filter, kernel_size=kernel, padding='same', \n",
    "                      kernel_regularizer=regularizer)(x)\n",
    "    if maxpooling_poolsize:\n",
    "        x = layers.MaxPooling2D(maxpooling_poolsize)(x)\n",
    "    # x = layers.BatchNormalization()(x)\n",
    "    if conv_act:\n",
    "        x = conv_act()(x)\n",
    "    if dense_units:\n",
    "        x = layers.Dense(dense_units, activation=dense_act)(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def convblock(x, conv_fn, filters, regularizer, conv_act, kernal=5):\n",
    "    '''\n",
    "    makes a block of convolution layers\n",
    "    \n",
    "    todo -- work on documentation \n",
    "    '''\n",
    "    count = 0\n",
    "    for _ in range(2):\n",
    "        for filter_ in filters:\n",
    "            count +=1\n",
    "            if count == 2:\n",
    "                x1 = conv_fn(x, filter_, kernal, regularizer, 2, conv_act,)\n",
    "                x = x1\n",
    "            else:\n",
    "                x = conv_fn(x, filter_, kernal, regularizer, None, conv_act)\n",
    "    x = layers.Add()([x, x1])\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gWaYlXqzRl5X"
   },
   "outputs": [],
   "source": [
    "def get_image_captions(params, images):\n",
    "    '''\n",
    "    creates captions to a group of images\n",
    "    \n",
    "    args:\n",
    "        params: dictionary with at least the following keys:\n",
    "            caption_text_input_length: int, length of captions\n",
    "            tokenizer_start_index: int, value to signal start of caption\n",
    "            tokenizer_end_index: int, value to signal end of caption\n",
    "            \n",
    "        images: tensor, dtype: tf.float32 shaped (None, 299, 299, 3) None is the \n",
    "        number of images, each image should be normalized to have\n",
    "        pixel values of -1 to 1. Images to be captioned\n",
    "\n",
    "            \n",
    "    returns:\n",
    "        captions: tensor, dtype float, shaped \n",
    "        (None, params['caption_text_input_length'])None is the number of \n",
    "        images, image caption sequences\n",
    "    '''\n",
    "    num_images = len(images)\n",
    "    caption_len = params['caption_text_input_length']\n",
    "    caption_end_index = params['tokenizer_end_index']\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    captions = list()\n",
    "    for image in range(num_images):\n",
    "        img = images[image]\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        txt_input = np.zeros((caption_len))\n",
    "        result = params['tokenizer_start_index']\n",
    "        for idx in range(caption_len):\n",
    "            txt_input[idx] = result\n",
    "            # with tf.device('/TPU:0'):\n",
    "            #     result = caption_step(img, txt_input)\n",
    "                # result = strategy.run(caption_step, args=(img, txt_input))\n",
    "            result = get_capt(img, txt_input)\n",
    "            result = result.values[0].numpy()[0]\n",
    "            if result == caption_end_index:\n",
    "                break\n",
    "        captions.append(txt_input)\n",
    "    captions = tf.convert_to_tensor(captions)\n",
    "    return captions\n",
    "        \n",
    "@tf.function\n",
    "def get_capt(img, txt):\n",
    "    def caption_step(image_, text_):\n",
    "        '''\n",
    "        evaluate model here\n",
    "        '''\n",
    "        txt_ = tf.expand_dims(text_, axis=0)\n",
    "        pred = caption_model((image_, txt_))\n",
    "\n",
    "\n",
    "        return pred\n",
    "    result = strategy.run(caption_step, args=(img, txt))\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHOtR_XA7182"
   },
   "outputs": [],
   "source": [
    "def create_model(params=params,\n",
    "                dense_nodes=100,\n",
    "                ltsm_units=128,\n",
    "                ltsm_dense_units=64):\n",
    "    '''\n",
    "    creates model with two inputs and out output\n",
    "\n",
    "        \n",
    "    '''\n",
    "    #set some fixed variables\n",
    "    text_input_shape = params['text_input']\n",
    "    vocab_size = params['vocab_size']\n",
    "    image_size = params['image_size']\n",
    "    object_maxlen = params['object_det_len']\n",
    "    caption_input_len = params['caption_text_input_length']\n",
    "    meme_text_len = params['meme_text_length']\n",
    "    caption_dim = params['caption_embedding_dim']\n",
    "    caption_vocab_size = params['caption_vocab_size']\n",
    "    \n",
    "    num_object_classes = 81\n",
    "\n",
    "    relu = layers.ReLU\n",
    "    leaky = layers.LeakyReLU\n",
    "    reg = keras.regularizers.l2(0.001,)\n",
    "    dense_act = 'tanh'\n",
    "    \n",
    "    #model inputs\n",
    "    input_text = layers.Input(text_input_shape, name='text_input')\n",
    "    embedding = layers.Embedding(input_dim=vocab_size, output_dim=64, \n",
    "                                 input_length=meme_text_len, mask_zero=True)(input_text)\n",
    "\n",
    "    \n",
    "    input_caption = layers.Input((caption_input_len,), name='caption_input')\n",
    "    embedding_caption = layers.Embedding(input_dim=caption_vocab_size, output_dim=caption_dim,\n",
    "                                         input_length=caption_input_len, mask_zero=True)(input_caption)\n",
    "    \n",
    "    #bidirectional LSTM - image captions\n",
    "    x_caption_bidir = embedding_caption\n",
    "    x_caption_bidir = layers.Bidirectional(layers.LSTM(ltsm_units))(x_caption_bidir)\n",
    "    # x_caption_bidir = layers.Dense(ltsm_dense_units, activation = 'relu')(x_caption_bidir)\n",
    "    x_caption_bidir_out = layers.Dense(dense_nodes, activation=dense_act,\n",
    "                                       name='bidirectional_caption_out')(x_caption_bidir)\n",
    "    x_caption_bidir_out = layers.LeakyReLU()(x_caption_bidir_out)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #bidirectional LSTM - original text\n",
    "    x_bidir = embedding\n",
    "    x_bidir = layers.Bidirectional(layers.LSTM(ltsm_units))(x_bidir)\n",
    "    # x_bidir = layers.Dense(ltsm_dense_units, activation = 'relu')(x_bidir)\n",
    "    x_bidir_out = layers.Dense(dense_nodes, activation=dense_act, name='bidirectional_out')(x_bidir)\n",
    "    x_bidir_out = layers.LeakyReLU()(x_bidir_out)\n",
    "\n",
    "    # #1D convolution - original text\n",
    "    # x_text = embedding\n",
    "    # x_text = pair_separableConv1D(x_text, 128, 4, 'relu', reg, None, 4)\n",
    "    # x_text = pair_separableConv1D(x_text, 128, 4, 'relu', None, None, 4)\n",
    "    # x_text = layers.Flatten()(x_text)\n",
    "    # # x_text = layers.Dense(dense_nodes, activation='tanh',kernel_regularizer=reg)(x_text)\n",
    "    # output_layer_text = layers.Dense(dense_nodes, activation='sigmoid', name='text_output')(x_text)\n",
    "\n",
    "    # #1D convolution - caption text\n",
    "    # x_text_caption = embedding_caption\n",
    "    # x_text_caption = pair_separableConv1D(x_text_caption, 128, 4, 'relu', reg, None, 4)\n",
    "    # x_text_caption = pair_separableConv1D(x_text_caption, 128, 4, 'relu', None, None, 4)\n",
    "    # x_text_caption = layers.Flatten()(x_text_caption)\n",
    "    # # x_text_caption = layers.Dense(dense_nodes, activation='tanh',kernel_regularizer=reg)(x_text_caption)\n",
    "    # x_caption_bidir_out_conv = layers.Dense(dense_nodes, activation='sigmoid', name='text_output_caption')(x_text_caption)\n",
    "\n",
    "    \n",
    "    \n",
    "    text_outputs = layers.Concatenate()([x_caption_bidir_out, x_bidir_out, ]) # Concatenate\n",
    "#     text_outputs = layers.Dense(dense_nodes)(text_outputs)\n",
    "    \n",
    "\n",
    "    x = text_outputs\n",
    "    \n",
    "    # x = layers.Reshape(( 2, dense_nodes))(x)\n",
    "    # x = layers.LSTM(64)(x)\n",
    "    x = layers.Dense(dense_nodes, activation=dense_act)(x)\n",
    "    # x = layers.LeakyReLU()(x)\n",
    "    # x = layers.Flatten()(x)\n",
    "    #consider adding an intrum dense layer here\n",
    "    final_output = layers.Dense(1, activation='sigmoid', name='final_out')(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    model = keras.Model([input_caption, input_text], final_output) #input_image\n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "    #           keras.metrics.FalsePositives(name='fp'),\n",
    "    #           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "    #           keras.metrics.Precision(name='precision'),\n",
    "    #           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = tf.keras.optimizers.schedules.ExponentialDecay(0.0003, 10 *3, 0.75)\n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(schedule),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "#\n",
    "def get_caption_model(params, client, bucket):\n",
    "    '''\n",
    "    creates pretrained image caption model\n",
    "    '''\n",
    "    \n",
    "    txt_input_length = params['caption_text_input_length']\n",
    "    model_num = params['caption_model_version']\n",
    "    model_path = 'image_caption_model_v{}.h5'.format(model_num)\n",
    "    if not os.path.isfile(model_path):\n",
    "        download_file(client, bucket,model_path)\n",
    "    \n",
    "    img_inp = layers.Input((*params['image_size'], 3), name='image_input')\n",
    "    inception = tf.keras.applications.InceptionV3(include_top=False, \n",
    "                                                  input_shape=(*params['image_size'], 3))\n",
    "    img_x = inception(img_inp)\n",
    "    img_x = layers.Reshape((64, 2048))(img_x)\n",
    "    \n",
    "    \n",
    "    txt_inp = layers.Input((txt_input_length,), name='text_input')\n",
    "    txt_x = txt_inp\n",
    "    \n",
    "    caption_model = tf.keras.models.load_model(model_path)\n",
    "    out = caption_model((img_x, txt_x))\n",
    "    out = tf.argmax(out, axis=-1, name='model_prediction')\n",
    "    \n",
    "    model = keras.Model([img_inp, txt_inp], out)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    return model\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_tHu8tJA7184"
   },
   "outputs": [],
   "source": [
    "train_files, valid_files = train_test_split(tfrecords,\n",
    "                              test_size=.2, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "alJt8bQV7185"
   },
   "outputs": [],
   "source": [
    "train_ds, train_steps = create_ds(train_files, params)\n",
    "valid_ds, valid_steps = create_ds(valid_files, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "S25BV5he7187",
    "outputId": "38ea40bd-821b-46a8-fb77-49c077b20d87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "caption_input (InputLayer)      [(None, 49)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "text_input (InputLayer)         [(None, 58)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_47 (Embedding)        (None, 49, 300)      3000000     caption_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "embedding_46 (Embedding)        (None, 58, 64)       1920000     text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 256)          439296      embedding_47[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 256)          197632      embedding_46[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_caption_out (Dens (None, 100)          25700       bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_out (Dense)       (None, 100)          25700       bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 100)          0           bidirectional_caption_out[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 100)          0           bidirectional_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 200)          0           leaky_re_lu_18[0][0]             \n",
      "                                                                 leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 100)          20100       concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "final_out (Dense)               (None, 1)            101         dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 5,628,529\n",
      "Trainable params: 5,628,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "np.random.seed(1)\n",
    "with strategy.scope():\n",
    "    model = create_model()\n",
    "    model.summary()\n",
    "    # caption_model = get_caption_model(params, client, 'jh_hateful_memes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbYqcMyy718-"
   },
   "outputs": [],
   "source": [
    "# for train_data, train_groundTruth in train_ds:\n",
    "#     for valid_data, valid_groundTruth in valid_ds:\n",
    "#         train_text, train_images = train_data\n",
    "#         train_groundtruth = train_groundTruth\n",
    "#         train_captions = get_image_captions(params, train_images)\n",
    "#         train_DATA = (train_captions, train_text)\n",
    "        \n",
    "        \n",
    "#         valid_text, valid_images  = valid_data\n",
    "#         valid_groundtruth = valid_groundTruth\n",
    "#         valid_captions = get_image_captions(params, valid_images)\n",
    "#         valid_DATA = (valid_captions, valid_text)\n",
    "        \n",
    "#         break\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7YF1k0iYgmFD",
    "outputId": "67903bfe-266b-46f8-9240-5da91cd84cf3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      " 1/25 [>.............................] - ETA: 0s - loss: 0.6984 - tp: 33.0000 - fn: 68.0000 - accuracy: 0.5809 - auc: 0.5078WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0402s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0402s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - ETA: 0s - loss: 0.6954 - tp: 1196.0000 - fn: 1276.0000 - accuracy: 0.5065 - auc: 0.5019WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0253s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_test_batch_end` time: 0.0253s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 9s 348ms/step - loss: 0.6954 - tp: 1196.0000 - fn: 1276.0000 - accuracy: 0.5065 - auc: 0.5019 - val_loss: 0.7072 - val_tp: 578.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.3400 - val_auc: 0.5608\n",
      "Epoch 2/250\n",
      "25/25 [==============================] - 2s 71ms/step - loss: 0.6902 - tp: 2320.0000 - fn: 152.0000 - accuracy: 0.4278 - auc: 0.6439 - val_loss: 0.6938 - val_tp: 443.0000 - val_fn: 135.0000 - val_accuracy: 0.4924 - val_auc: 0.6109\n",
      "Epoch 3/250\n",
      "25/25 [==============================] - 2s 68ms/step - loss: 0.6585 - tp: 1725.0000 - fn: 747.0000 - accuracy: 0.6350 - auc: 0.7048 - val_loss: 0.6466 - val_tp: 244.0000 - val_fn: 334.0000 - val_accuracy: 0.6465 - val_auc: 0.6309\n",
      "Epoch 4/250\n",
      "25/25 [==============================] - 2s 69ms/step - loss: 0.5771 - tp: 1594.0000 - fn: 878.0000 - accuracy: 0.7351 - auc: 0.7946 - val_loss: 0.6911 - val_tp: 332.0000 - val_fn: 246.0000 - val_accuracy: 0.5982 - val_auc: 0.6419\n",
      "Epoch 5/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.5103 - tp: 1830.0000 - fn: 642.0000 - accuracy: 0.7684 - auc: 0.8423 - val_loss: 0.7033 - val_tp: 307.0000 - val_fn: 271.0000 - val_accuracy: 0.6129 - val_auc: 0.6388\n",
      "Epoch 6/250\n",
      "25/25 [==============================] - 2s 70ms/step - loss: 0.4689 - tp: 1926.0000 - fn: 546.0000 - accuracy: 0.7915 - auc: 0.8704 - val_loss: 0.7210 - val_tp: 313.0000 - val_fn: 265.0000 - val_accuracy: 0.6147 - val_auc: 0.6450\n",
      "Epoch 7/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.4397 - tp: 1951.0000 - fn: 521.0000 - accuracy: 0.8065 - auc: 0.8871 - val_loss: 0.7390 - val_tp: 293.0000 - val_fn: 285.0000 - val_accuracy: 0.6212 - val_auc: 0.6380\n",
      "Epoch 8/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.4204 - tp: 2008.0000 - fn: 464.0000 - accuracy: 0.8122 - auc: 0.8967 - val_loss: 0.7626 - val_tp: 314.0000 - val_fn: 264.0000 - val_accuracy: 0.6218 - val_auc: 0.6419\n",
      "Epoch 9/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.4066 - tp: 2025.0000 - fn: 447.0000 - accuracy: 0.8187 - auc: 0.9040 - val_loss: 0.7812 - val_tp: 308.0000 - val_fn: 270.0000 - val_accuracy: 0.6182 - val_auc: 0.6406\n",
      "Epoch 10/250\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.3968 - tp: 2038.0000 - fn: 434.0000 - accuracy: 0.8218 - auc: 0.9083 - val_loss: 0.7896 - val_tp: 305.0000 - val_fn: 273.0000 - val_accuracy: 0.6253 - val_auc: 0.6370\n",
      "Epoch 11/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3889 - tp: 2076.0000 - fn: 396.0000 - accuracy: 0.8240 - auc: 0.9123 - val_loss: 0.7992 - val_tp: 304.0000 - val_fn: 274.0000 - val_accuracy: 0.6235 - val_auc: 0.6366\n",
      "Epoch 12/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.3832 - tp: 2057.0000 - fn: 415.0000 - accuracy: 0.8284 - auc: 0.9148 - val_loss: 0.8196 - val_tp: 313.0000 - val_fn: 265.0000 - val_accuracy: 0.6106 - val_auc: 0.6382\n",
      "Epoch 13/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3785 - tp: 2073.0000 - fn: 399.0000 - accuracy: 0.8301 - auc: 0.9169 - val_loss: 0.8222 - val_tp: 312.0000 - val_fn: 266.0000 - val_accuracy: 0.6165 - val_auc: 0.6369\n",
      "Epoch 14/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3751 - tp: 2082.0000 - fn: 390.0000 - accuracy: 0.8310 - auc: 0.9185 - val_loss: 0.8289 - val_tp: 312.0000 - val_fn: 266.0000 - val_accuracy: 0.6159 - val_auc: 0.6366\n",
      "Epoch 15/250\n",
      "25/25 [==============================] - 1s 58ms/step - loss: 0.3724 - tp: 2084.0000 - fn: 388.0000 - accuracy: 0.8319 - auc: 0.9196 - val_loss: 0.8341 - val_tp: 312.0000 - val_fn: 266.0000 - val_accuracy: 0.6171 - val_auc: 0.6355\n",
      "Epoch 16/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3703 - tp: 2098.0000 - fn: 374.0000 - accuracy: 0.8340 - auc: 0.9206 - val_loss: 0.8355 - val_tp: 309.0000 - val_fn: 269.0000 - val_accuracy: 0.6176 - val_auc: 0.6350\n",
      "Epoch 17/250\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.3688 - tp: 2086.0000 - fn: 386.0000 - accuracy: 0.8341 - auc: 0.9213 - val_loss: 0.8387 - val_tp: 307.0000 - val_fn: 271.0000 - val_accuracy: 0.6153 - val_auc: 0.6350\n",
      "Epoch 18/250\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 0.3676 - tp: 2088.0000 - fn: 384.0000 - accuracy: 0.8341 - auc: 0.9218 - val_loss: 0.8410 - val_tp: 308.0000 - val_fn: 270.0000 - val_accuracy: 0.6159 - val_auc: 0.6347\n",
      "Epoch 19/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3668 - tp: 2087.0000 - fn: 385.0000 - accuracy: 0.8346 - auc: 0.9222 - val_loss: 0.8415 - val_tp: 309.0000 - val_fn: 269.0000 - val_accuracy: 0.6171 - val_auc: 0.6345\n",
      "Epoch 20/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.3659 - tp: 2090.0000 - fn: 382.0000 - accuracy: 0.8344 - auc: 0.9225 - val_loss: 0.8441 - val_tp: 311.0000 - val_fn: 267.0000 - val_accuracy: 0.6176 - val_auc: 0.6344\n",
      "Epoch 21/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3654 - tp: 2096.0000 - fn: 376.0000 - accuracy: 0.8349 - auc: 0.9228 - val_loss: 0.8454 - val_tp: 311.0000 - val_fn: 267.0000 - val_accuracy: 0.6176 - val_auc: 0.6343\n",
      "Epoch 22/250\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.3649 - tp: 2093.0000 - fn: 379.0000 - accuracy: 0.8349 - auc: 0.9229 - val_loss: 0.8454 - val_tp: 309.0000 - val_fn: 269.0000 - val_accuracy: 0.6171 - val_auc: 0.6341\n",
      "Epoch 23/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.3646 - tp: 2094.0000 - fn: 378.0000 - accuracy: 0.8350 - auc: 0.9231 - val_loss: 0.8465 - val_tp: 311.0000 - val_fn: 267.0000 - val_accuracy: 0.6176 - val_auc: 0.6342\n",
      "Epoch 24/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3643 - tp: 2094.0000 - fn: 378.0000 - accuracy: 0.8350 - auc: 0.9232 - val_loss: 0.8469 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6342\n",
      "Epoch 25/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.3641 - tp: 2094.0000 - fn: 378.0000 - accuracy: 0.8351 - auc: 0.9233 - val_loss: 0.8474 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6342\n",
      "Epoch 26/250\n",
      "25/25 [==============================] - 2s 63ms/step - loss: 0.3639 - tp: 2094.0000 - fn: 378.0000 - accuracy: 0.8350 - auc: 0.9234 - val_loss: 0.8479 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6342\n",
      "Epoch 27/250\n",
      "25/25 [==============================] - 2s 61ms/step - loss: 0.3638 - tp: 2095.0000 - fn: 377.0000 - accuracy: 0.8351 - auc: 0.9234 - val_loss: 0.8480 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6340\n",
      "Epoch 28/250\n",
      "25/25 [==============================] - 2s 64ms/step - loss: 0.3637 - tp: 2094.0000 - fn: 378.0000 - accuracy: 0.8350 - auc: 0.9235 - val_loss: 0.8482 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6340\n",
      "Epoch 29/250\n",
      "25/25 [==============================] - 2s 62ms/step - loss: 0.3636 - tp: 2096.0000 - fn: 376.0000 - accuracy: 0.8353 - auc: 0.9235 - val_loss: 0.8484 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6340\n",
      "Epoch 30/250\n",
      "25/25 [==============================] - 2s 65ms/step - loss: 0.3636 - tp: 2096.0000 - fn: 376.0000 - accuracy: 0.8354 - auc: 0.9235 - val_loss: 0.8484 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6341\n",
      "Epoch 31/250\n",
      "25/25 [==============================] - 3s 126ms/step - loss: 0.3635 - tp: 2096.0000 - fn: 376.0000 - accuracy: 0.8351 - auc: 0.9236 - val_loss: 0.8486 - val_tp: 310.0000 - val_fn: 268.0000 - val_accuracy: 0.6171 - val_auc: 0.6341\n"
     ]
    }
   ],
   "source": [
    "#calculate class weights\n",
    "target_0 = 5450 #these values will not change (are from review of test ds)\n",
    "target_1 = 3050\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "\n",
    "#early stopping if validation auc stops improving\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=25,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "# (text, image), label\n",
    "history = model.fit(train_DATA, \n",
    "                    train_groundtruth, \n",
    "                    steps_per_epoch=25, \n",
    "                    validation_data=(valid_DATA, valid_groundtruth), \n",
    "                    validation_steps=5,\n",
    "                    callbacks=[early_stopping],\n",
    "                    class_weight=class_weights,\n",
    "                    epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WNQKf2Y08zw2"
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 803
    },
    "colab_type": "code",
    "id": "_BG-kKjK83qC",
    "outputId": "54fc3b65-acd5-4f04-aebd-82ca353fc471"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NjL-SsIv-K5O",
    "outputId": "bef94531-8b21-43b0-e78e-6f248c63f5c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6449816226959229"
      ]
     },
     "execution_count": 177,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(history.history['val_auc']) #relu - 0.664/0.653/0.635 // tanh + leaky -- 0.651/0.661/0.649 // leaky -- 0.6506/0.656/0.648\n",
    "#tanh - 0.658 / .649 / 0.651\n",
    "#conv - relu -  0.652 // tanh - 0.638"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bE6q1VFf-ME7"
   },
   "outputs": [],
   "source": [
    "params['version'] = 10\n",
    "model_name = 'model_hateful_memes_v{}.h5'.format(params['version'])\n",
    "model.save(model_name)\n",
    "bucket = client.bucket('jh_hateful_memes')\n",
    "blob = bucket.blob(model_name)\n",
    "blob.upload_from_filename(model_name)#fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Dh9c21R6lEZc",
    "outputId": "f9c235da-3df2-497c-892a-a5e00158d8a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "#make into a fn\n",
    "bucket = 'jh_hateful_memes_test'\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n",
    "objects = client.list_blobs(bucket, prefix='hatefulmemes_')\n",
    "tfrecords = []\n",
    "for object_ in objects:\n",
    "    path = str(object_).split(', ')[1]\n",
    "    gs_path = os.path.join('gs://', bucket, path)\n",
    "    tfrecords.append(gs_path) #gs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jU-hPa_8lMNP"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcVbjWe8i-Kr"
   },
   "outputs": [],
   "source": [
    "test_ds, test_steps = create_ds(tfrecords, params, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "or7-zGBVlppw"
   },
   "outputs": [],
   "source": [
    "for x_test, ids in test_ds:\n",
    "\n",
    "    test_text, test_images = x_test\n",
    "    test_captions = get_image_captions(params, test_images)\n",
    "    test_DATA = (test_captions, test_text)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    predictions = model.predict(test_DATA, steps=10)\n",
    "    prediction_ids = ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ABcoxiAH_le8"
   },
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'id': prediction_ids,\n",
    "    'proba': np.concatenate(predictions),\n",
    "    'label': np.ones(1000, int)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UC0AiCcELFFD"
   },
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLP_Ok09Rl5y"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZBoY68f46Wuk"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "two_input_model (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
