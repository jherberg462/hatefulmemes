{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJiMk2hxVVdH"
   },
   "outputs": [],
   "source": [
    "#download glove model from http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip and\n",
    "#upload to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Iy1dZ-XUJHsF",
    "outputId": "bc9492d8-d1e8-4480-a874-d48e732dd621"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "#set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#accessing files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#display charts/images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#don't need\n",
    "# from tensorflow.python.keras.preprocessing import sequence\n",
    "# from tensorflow.python.keras.preprocessing import text\n",
    "# import tensorflow_hub as hub\n",
    "\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ig0i-YXvJHsO"
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'image_size': [256, 256],\n",
    "    'vocab_size': 10000,\n",
    "    'text_input_length': 49,\n",
    "    'nodes': 256,\n",
    "    'tokenizer_start_index': 58, #index of tokenizer to signal sequence start\n",
    "    'tokenizer_end_index': 57,\n",
    "    'epochs': 20,\n",
    "    'version': 6,\n",
    "    'embedding_dim': 300,\n",
    "    'ds_size': 801592,\n",
    "    'batch_size': 5343\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-0QY626PJHsU"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k3pADpk0JHsa"
   },
   "outputs": [],
   "source": [
    "training_bucket = 'gs://kds-e7996502fe373b391a0a14641ad5f932ee7d607744dbe970cc8ffe08'\n",
    "glove_bucket = 'gs://kds-5123f8991f380aa8ec3a0dfae64a3732b529d4e504450dd8f9e55fb1'\n",
    "tfrecords = tf.io.gfile.glob(training_bucket + '/*tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XOOAMRQe7Nob",
    "outputId": "9689538f-e38b-47d0-9f93-e4ad65caaeda"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://kds-5123f8991f380aa8ec3a0dfae64a3732b529d4e504450dd8f9e55fb1/glove.840B.300d.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.gfile.glob(glove_bucket + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "6t9Kv3FyJHse",
    "outputId": "2eaf0100-cd11-474c-fc42-51af3e6efb0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.2.56.130:8470\n",
      "INFO:tensorflow:Initializing the TPU system: grpc://10.2.56.130:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.2.56.130:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "arYwtpLjJHsi"
   },
   "outputs": [],
   "source": [
    "def decode_example(example):\n",
    "    '''\n",
    "    decodes single tfexample from TFrecord file\n",
    "    '''\n",
    "    features = {'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'inception': tf.io.FixedLenFeature([], tf.string), #can also be vgg\n",
    "                'y': tf.io.FixedLenFeature([], tf.string)}\n",
    "    single_example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    text = tf.io.parse_tensor(single_example['text'], out_type=tf.int32)\n",
    "    text = tf.cast(text, tf.float32)\n",
    "    image_features = tf.io.parse_tensor(single_example['inception'], out_type=tf.float32)\n",
    "    y_value = tf.io.parse_tensor(single_example['y'], out_type=tf.int32)\n",
    "    y_value = tf.expand_dims(y_value, axis=0)\n",
    "\n",
    "    return (image_features, text), y_value\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HVGvXnmBJHsk"
   },
   "outputs": [],
   "source": [
    "def create_ds(files, params):\n",
    "    '''\n",
    "    function to create dataset for training/validation\n",
    "    \n",
    "    args:\n",
    "        files: list of str, filepaths of TFrecord files to be used in DS\n",
    "        params: dict with the following keys:\n",
    "            batch_size: int, batch size of training/validation step\n",
    "            examples_per_file: int, number of examples in each TFrecord file\n",
    "        train, bool, default True, indicator if the DS is for training\n",
    "        test_examples, int: default 1000 number of examples in test dataset\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images, text and labels\n",
    "            output of ds is: (text, image), label\n",
    "        ds_batches: int, number of steps in each epoch based on the batch_size\n",
    "    '''\n",
    "    # batch_size = params['batch_size']\n",
    "    batch_size = params['ds_size']\n",
    "\n",
    "    ds = tf.data.TFRecordDataset(filenames = files)\n",
    "    ds = ds.map(decode_example, \n",
    "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "#     ds = ds.cache() \n",
    "    \n",
    "    return ds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NKHCPu3cZf57"
   },
   "outputs": [],
   "source": [
    "def download_file(bucket, file_name):\n",
    "    '''\n",
    "    downloads a file from a public GCS bucket into working directory\n",
    "\n",
    "    args:\n",
    "        bucket: str, name of bucket to download file from\n",
    "        file_name: str, file name to download\n",
    "    returns: None\n",
    "    \n",
    "    '''\n",
    "    file_path = tf.io.gfile.glob(bucket + '/' + file_name)[0]\n",
    "    tf.io.gfile.copy(file_path, file_name)\n",
    "\n",
    "def create_tokenizer_from_filename(file_name,\n",
    "                                  bucket=None):\n",
    "    '''\n",
    "    creates tf.keras.preprocessing.text.tokenizer from a \n",
    "    json config file in current working directory\n",
    "    args:\n",
    "        file_name: str, filename where config json file is located\n",
    "        bucket, str, default None, name of GCS bucket with an object with the\n",
    "            same file name as glove_file, if an arg\n",
    "            is passed, function will first check if file_name exists in current\n",
    "            directory, and if not, will download an object located at file_name\n",
    "            in the bucket passed into bucket arg\n",
    "    returns:\n",
    "        tokenizer object\n",
    "    '''\n",
    "    if bucket:\n",
    "        if not os.path.isfile(file_name):\n",
    "            download_file(bucket,file_name)\n",
    "    with open(file_name) as file:\n",
    "        open_file = json.load(file)\n",
    "        tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(open_file)\n",
    "    return tokenizer\n",
    "\n",
    "def get_embedding_weights_from_tokenizer_glove(glove_file,\n",
    "                                              tokenizer,\n",
    "                                              embedding_dim,\n",
    "                                              bucket=None,\n",
    "                                              ):\n",
    "    '''\n",
    "    gets the weights to use in an embedding layer from a pretained\n",
    "    model based on the tokenizer used to create sequences that will\n",
    "    be passed into embedding layer\n",
    "    \n",
    "    args:\n",
    "        glove_file: str, path of pretrained model from current directory\n",
    "        tokenizer: tf.keras.preprocessing.text.tokenizer object, tokenizer\n",
    "            that was used to create sequences\n",
    "        embedding_dim: int, output_dim of embedding layer of pre-trained model\n",
    "        bucket, str, default None, name of GCS bucket with an object with the\n",
    "            same file name as glove_file, if an arg\n",
    "            is passed, function will first check if glove_file exists in current\n",
    "            directory, and if not, will download an object located at glove_file\n",
    "            in the bucket passed into bucket arg\n",
    "    returns: \n",
    "        embedding_weights: numpy array, shaped* (vocab_size, embedding_dim)\n",
    "            weights that can be used for embedding layer\n",
    "            *vocab_size = tokenizer.num_words which is the number of words in\n",
    "            the tokenizer vocabulary\n",
    "        \n",
    "    '''\n",
    "    if bucket:\n",
    "        if not os.path.isfile(glove_file):\n",
    "            download_file(bucket, glove_file)\n",
    "    word_values = dict()\n",
    "    file = open(glove_file, encoding='utf-8')\n",
    "    \n",
    "    for line in file:\n",
    "        coeff = line.split()\n",
    "        word = coeff[0]\n",
    "        coefficients = np.asarray(coeff[-embedding_dim:], dtype='float32')\n",
    "        word_values[word] = coefficients\n",
    "    file.close()\n",
    "    vocab_size = tokenizer.num_words\n",
    "    embedding_weights = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if idx < vocab_size:\n",
    "            word_embedding_values = word_values.get(word)\n",
    "            if word_embedding_values is not None:\n",
    "                embedding_weights[idx] = word_embedding_values\n",
    "    \n",
    "    return embedding_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kx474nk2JHsm"
   },
   "outputs": [],
   "source": [
    "ds = create_ds(tfrecords, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NKb5yx6PJHsr"
   },
   "outputs": [],
   "source": [
    "def create_model(params, embedding_weights=None):\n",
    "    '''\n",
    "    creates model to caption images\n",
    "    '''\n",
    "    vocab_size = params['vocab_size']\n",
    "    txt_input_length = params['text_input_length']\n",
    "    nodes = params['nodes']\n",
    "    embedding_dim = params['embedding_dim']\n",
    "\n",
    "    image_feature_inp = layers.Input((2048,), name='features_input')\n",
    "    \n",
    "    \n",
    "    txt_inp = layers.Input((txt_input_length,), name='text_input')\n",
    "    embedding = layers.Embedding(vocab_size, embedding_dim, mask_zero=True)(txt_inp)\n",
    "\n",
    "    \n",
    "    encoder = layers.Dense(embedding_dim, activation='relu')(embedding)\n",
    "    \n",
    "    w1 = layers.Dense(nodes)(image_feature_inp)\n",
    "    w2 = layers.Dense(nodes)(encoder)\n",
    "    attention = layers.Add()([w1, w2])\n",
    "    attention = layers.Dense(1)(attention)\n",
    "    attention = tf.nn.tanh(attention)\n",
    "    encoder_model = keras.Model([txt_inp, image_feature_inp], [attention, encoder])\n",
    "    \n",
    "    image_context_input = layers.Input((embedding_dim,), name='context_vector')\n",
    "    image_context = tf.expand_dims(image_context_input, 1)\n",
    "    \n",
    "    x = tf.concat([image_context, embedding], axis=1)\n",
    "    x, _ = layers.GRU(units=nodes, return_sequences=False, return_state=True)(x)\n",
    "    x = layers.Dense(nodes)(x)\n",
    "    decoder_output = layers.Dense(vocab_size)(x)\n",
    "    decoder_model = keras.Model([image_context_input, txt_inp], [decoder_output])\n",
    "    if embedding_weights is not None:\n",
    "        decoder_model.layers[3].set_weights([embedding_weights])\n",
    "        decoder_model.layers[3].trainable = False\n",
    "        \n",
    "        encoder_model.layers[1].set_weights([embedding_weights])\n",
    "        encoder_model.layers[1].trainable = False\n",
    "\n",
    "    image_input = layers.Input(2048, name='image_input')\n",
    "    text_input = layers.Input(params['text_input_length'], name='text_input')\n",
    "    attention_output, encoder_output = encoder_model((text_input, image_input))\n",
    "    attention_weights = tf.nn.softmax(attention_output, axis=1)\n",
    "    # context_vector = attention_weights * encoder_output\n",
    "    context_vector = tf.multiply(x=attention_weights, y=encoder_output)\n",
    "    context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "    preds = decoder_model((context_vector, text_input))\n",
    "    final_model = keras.Model([image_input, text_input], preds)\n",
    "    # final_model.compile(optimizer='adam',loss='SparseCategoricalCrossentropy')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-8DlDjMDZf6A"
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer_from_filename('coco_tokenizer.json', \n",
    "                                           training_bucket)\n",
    "embedding_weights = get_embedding_weights_from_tokenizer_glove('glove.840B.300d.txt',\n",
    "                                                               tokenizer,\n",
    "                                                               300,\n",
    "                                                               glove_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JkmvmncofYQM"
   },
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    '''\n",
    "    taken from https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
    "    '''\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    loss = tf.reduce_mean(loss_)\n",
    "    #update loss tracker\n",
    "    # loss_tracker.update_state(loss)\n",
    "\n",
    "    return loss\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "-3DhhxMuIsru"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    # encoder, decoder = create_model(params, embedding_weights) #embedding_weights\n",
    "    model = create_model(params, embedding_weights)\n",
    "    optimizer = tf.keras.optimizers.Adam(0.0005)\n",
    "    model.compile(optimizer='adam', loss=loss_function)\n",
    "    # loss_tracker = tf.keras.metrics.Mean(name='loss')\n",
    "    # model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "bVGtPCLSJHst",
    "outputId": "1c94b37f-a78d-4bad-c0bd-cc23fa57a3b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r  1/150 [..............................] - ETA: 14:48 - loss: 9.2104WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0462s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0020s vs `on_train_batch_end` time: 0.0462s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 18s 119ms/step - loss: 5.8032\n",
      "Epoch 2/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 5.4400\n",
      "Epoch 3/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 5.3210\n",
      "Epoch 4/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 4.8410\n",
      "Epoch 5/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 4.2100\n",
      "Epoch 6/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.7964\n",
      "Epoch 7/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.5488\n",
      "Epoch 8/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.3971\n",
      "Epoch 9/400\n",
      "150/150 [==============================] - 7s 49ms/step - loss: 3.2959\n",
      "Epoch 10/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.2104\n",
      "Epoch 11/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.1448\n",
      "Epoch 12/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.0885\n",
      "Epoch 13/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 3.0414\n",
      "Epoch 14/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.9994\n",
      "Epoch 15/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.9645\n",
      "Epoch 16/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.9305\n",
      "Epoch 17/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.9003\n",
      "Epoch 18/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.8727\n",
      "Epoch 19/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.8453\n",
      "Epoch 20/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.8207\n",
      "Epoch 21/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.7986\n",
      "Epoch 22/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.7754\n",
      "Epoch 23/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.7552\n",
      "Epoch 24/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.7368\n",
      "Epoch 25/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.7181\n",
      "Epoch 26/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6995\n",
      "Epoch 27/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6822\n",
      "Epoch 28/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6648\n",
      "Epoch 29/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6497\n",
      "Epoch 30/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6342\n",
      "Epoch 31/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6190\n",
      "Epoch 32/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.6039\n",
      "Epoch 33/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.5891\n",
      "Epoch 34/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.5761\n",
      "Epoch 35/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.5613\n",
      "Epoch 36/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.5477\n",
      "Epoch 37/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.5356\n",
      "Epoch 38/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.5222\n",
      "Epoch 39/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.5087\n",
      "Epoch 40/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4969\n",
      "Epoch 41/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4844\n",
      "Epoch 42/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4720\n",
      "Epoch 43/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4609\n",
      "Epoch 44/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4479\n",
      "Epoch 45/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4366\n",
      "Epoch 46/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4255\n",
      "Epoch 47/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4133\n",
      "Epoch 48/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.4031\n",
      "Epoch 49/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3919\n",
      "Epoch 50/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3813\n",
      "Epoch 51/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3701\n",
      "Epoch 52/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3598\n",
      "Epoch 53/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3494\n",
      "Epoch 54/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.3395\n",
      "Epoch 55/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3284\n",
      "Epoch 56/400\n",
      "150/150 [==============================] - 7s 48ms/step - loss: 2.3184\n",
      "Epoch 57/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.3078\n",
      "Epoch 58/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2990\n",
      "Epoch 59/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2891\n",
      "Epoch 60/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2792\n",
      "Epoch 61/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2693\n",
      "Epoch 62/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2610\n",
      "Epoch 63/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2500\n",
      "Epoch 64/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2416\n",
      "Epoch 65/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2323\n",
      "Epoch 66/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2224\n",
      "Epoch 67/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2152\n",
      "Epoch 68/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.2064\n",
      "Epoch 69/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1971\n",
      "Epoch 70/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1897\n",
      "Epoch 71/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1815\n",
      "Epoch 72/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1735\n",
      "Epoch 73/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1646\n",
      "Epoch 74/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1562\n",
      "Epoch 75/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1477\n",
      "Epoch 76/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1410\n",
      "Epoch 77/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1343\n",
      "Epoch 78/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.1265\n",
      "Epoch 79/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.1190\n",
      "Epoch 80/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.1131\n",
      "Epoch 81/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.1039\n",
      "Epoch 82/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0986\n",
      "Epoch 83/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0922\n",
      "Epoch 84/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0836\n",
      "Epoch 85/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0815\n",
      "Epoch 86/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.0739\n",
      "Epoch 87/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0660\n",
      "Epoch 88/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0604\n",
      "Epoch 89/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0544\n",
      "Epoch 90/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0469\n",
      "Epoch 91/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0402\n",
      "Epoch 92/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.0352\n",
      "Epoch 93/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0320\n",
      "Epoch 94/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0243\n",
      "Epoch 95/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0191\n",
      "Epoch 96/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0128\n",
      "Epoch 97/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 2.0087\n",
      "Epoch 98/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 2.0047\n",
      "Epoch 99/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.9988\n",
      "Epoch 100/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9917\n",
      "Epoch 101/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9864\n",
      "Epoch 102/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9841\n",
      "Epoch 103/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9800\n",
      "Epoch 104/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9746\n",
      "Epoch 105/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9685\n",
      "Epoch 106/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9687\n",
      "Epoch 107/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9608\n",
      "Epoch 108/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9544\n",
      "Epoch 109/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9527\n",
      "Epoch 110/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9479\n",
      "Epoch 111/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9446\n",
      "Epoch 112/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9414\n",
      "Epoch 113/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9352\n",
      "Epoch 114/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.9311\n",
      "Epoch 115/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9274\n",
      "Epoch 116/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.9234\n",
      "Epoch 117/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9201\n",
      "Epoch 118/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9163\n",
      "Epoch 119/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9132\n",
      "Epoch 120/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9096\n",
      "Epoch 121/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.9039\n",
      "Epoch 122/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.9013\n",
      "Epoch 123/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8962\n",
      "Epoch 124/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8939\n",
      "Epoch 125/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8921\n",
      "Epoch 126/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8934\n",
      "Epoch 127/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8918\n",
      "Epoch 128/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8862\n",
      "Epoch 129/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8777\n",
      "Epoch 130/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8742\n",
      "Epoch 131/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8724\n",
      "Epoch 132/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8697\n",
      "Epoch 133/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8684\n",
      "Epoch 134/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8648\n",
      "Epoch 135/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8583\n",
      "Epoch 136/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8573\n",
      "Epoch 137/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8568\n",
      "Epoch 138/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8545\n",
      "Epoch 139/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8536\n",
      "Epoch 140/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8462\n",
      "Epoch 141/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8428\n",
      "Epoch 142/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8440\n",
      "Epoch 143/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8380\n",
      "Epoch 144/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8357\n",
      "Epoch 145/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8333\n",
      "Epoch 146/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8299\n",
      "Epoch 147/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8315\n",
      "Epoch 148/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8245\n",
      "Epoch 149/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8252\n",
      "Epoch 150/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.8231\n",
      "Epoch 151/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8232\n",
      "Epoch 152/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8177\n",
      "Epoch 153/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8122\n",
      "Epoch 154/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8108\n",
      "Epoch 155/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8104\n",
      "Epoch 156/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8091\n",
      "Epoch 157/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8095\n",
      "Epoch 158/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.8032\n",
      "Epoch 159/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7979\n",
      "Epoch 160/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7984\n",
      "Epoch 161/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7966\n",
      "Epoch 162/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7949\n",
      "Epoch 163/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7923\n",
      "Epoch 164/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7911\n",
      "Epoch 165/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7932\n",
      "Epoch 166/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7890\n",
      "Epoch 167/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7831\n",
      "Epoch 168/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7876\n",
      "Epoch 169/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7815\n",
      "Epoch 170/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7755\n",
      "Epoch 171/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7808\n",
      "Epoch 172/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7754\n",
      "Epoch 173/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7744\n",
      "Epoch 174/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7710\n",
      "Epoch 175/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7679\n",
      "Epoch 176/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7685\n",
      "Epoch 177/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7714\n",
      "Epoch 178/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7659\n",
      "Epoch 179/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7656\n",
      "Epoch 180/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7637\n",
      "Epoch 181/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7584\n",
      "Epoch 182/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7639\n",
      "Epoch 183/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7573\n",
      "Epoch 184/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7543\n",
      "Epoch 185/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7550\n",
      "Epoch 186/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7507\n",
      "Epoch 187/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7544\n",
      "Epoch 188/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7486\n",
      "Epoch 189/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7468\n",
      "Epoch 190/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7487\n",
      "Epoch 191/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7464\n",
      "Epoch 192/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7413\n",
      "Epoch 193/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7375\n",
      "Epoch 194/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7453\n",
      "Epoch 195/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7406\n",
      "Epoch 196/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7399\n",
      "Epoch 197/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7482\n",
      "Epoch 198/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7402\n",
      "Epoch 199/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7322\n",
      "Epoch 200/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7258\n",
      "Epoch 201/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7272\n",
      "Epoch 202/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7242\n",
      "Epoch 203/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7282\n",
      "Epoch 204/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7269\n",
      "Epoch 205/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7221\n",
      "Epoch 206/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7393\n",
      "Epoch 207/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7250\n",
      "Epoch 208/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7207\n",
      "Epoch 209/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7188\n",
      "Epoch 210/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7212\n",
      "Epoch 211/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7178\n",
      "Epoch 212/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7130\n",
      "Epoch 213/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7142\n",
      "Epoch 214/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7124\n",
      "Epoch 215/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7108\n",
      "Epoch 216/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7115\n",
      "Epoch 217/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7120\n",
      "Epoch 218/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7067\n",
      "Epoch 219/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7115\n",
      "Epoch 220/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7059\n",
      "Epoch 221/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7092\n",
      "Epoch 222/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7084\n",
      "Epoch 223/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7044\n",
      "Epoch 224/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6984\n",
      "Epoch 225/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6990\n",
      "Epoch 226/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6991\n",
      "Epoch 227/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6935\n",
      "Epoch 228/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6940\n",
      "Epoch 229/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7021\n",
      "Epoch 230/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7003\n",
      "Epoch 231/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6961\n",
      "Epoch 232/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6963\n",
      "Epoch 233/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6932\n",
      "Epoch 234/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6892\n",
      "Epoch 235/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6879\n",
      "Epoch 236/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6891\n",
      "Epoch 237/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6861\n",
      "Epoch 238/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6876\n",
      "Epoch 239/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7055\n",
      "Epoch 240/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6846\n",
      "Epoch 241/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6796\n",
      "Epoch 242/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6807\n",
      "Epoch 243/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7050\n",
      "Epoch 244/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6881\n",
      "Epoch 245/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6757\n",
      "Epoch 246/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6884\n",
      "Epoch 247/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6767\n",
      "Epoch 248/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6702\n",
      "Epoch 249/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6721\n",
      "Epoch 250/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6675\n",
      "Epoch 251/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6712\n",
      "Epoch 252/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6723\n",
      "Epoch 253/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6782\n",
      "Epoch 254/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6812\n",
      "Epoch 255/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6797\n",
      "Epoch 256/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6661\n",
      "Epoch 257/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6709\n",
      "Epoch 258/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6686\n",
      "Epoch 259/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6630\n",
      "Epoch 260/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6739\n",
      "Epoch 261/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6672\n",
      "Epoch 262/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6645\n",
      "Epoch 263/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6658\n",
      "Epoch 264/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6658\n",
      "Epoch 265/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6593\n",
      "Epoch 266/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6661\n",
      "Epoch 267/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6567\n",
      "Epoch 268/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6643\n",
      "Epoch 269/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6593\n",
      "Epoch 270/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6551\n",
      "Epoch 271/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6540\n",
      "Epoch 272/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6595\n",
      "Epoch 273/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6807\n",
      "Epoch 274/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6482\n",
      "Epoch 275/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6573\n",
      "Epoch 276/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6567\n",
      "Epoch 277/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6496\n",
      "Epoch 278/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6434\n",
      "Epoch 279/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6468\n",
      "Epoch 280/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.7512\n",
      "Epoch 281/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.7109\n",
      "Epoch 282/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6444\n",
      "Epoch 283/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6325\n",
      "Epoch 284/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6410\n",
      "Epoch 285/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6400\n",
      "Epoch 286/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6398\n",
      "Epoch 287/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6390\n",
      "Epoch 288/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6394\n",
      "Epoch 289/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6473\n",
      "Epoch 290/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6388\n",
      "Epoch 291/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6409\n",
      "Epoch 292/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6554\n",
      "Epoch 293/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6486\n",
      "Epoch 294/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6372\n",
      "Epoch 295/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6337\n",
      "Epoch 296/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6327\n",
      "Epoch 297/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6373\n",
      "Epoch 298/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6414\n",
      "Epoch 299/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6354\n",
      "Epoch 300/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6307\n",
      "Epoch 301/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6308\n",
      "Epoch 302/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6392\n",
      "Epoch 303/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6395\n",
      "Epoch 304/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6306\n",
      "Epoch 305/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6347\n",
      "Epoch 306/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6287\n",
      "Epoch 307/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6345\n",
      "Epoch 308/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6343\n",
      "Epoch 309/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6331\n",
      "Epoch 310/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6258\n",
      "Epoch 311/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6235\n",
      "Epoch 312/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6267\n",
      "Epoch 313/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6326\n",
      "Epoch 314/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6303\n",
      "Epoch 315/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6400\n",
      "Epoch 316/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6295\n",
      "Epoch 317/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6261\n",
      "Epoch 318/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6183\n",
      "Epoch 319/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6190\n",
      "Epoch 320/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6177\n",
      "Epoch 321/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6516\n",
      "Epoch 322/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6349\n",
      "Epoch 323/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6236\n",
      "Epoch 324/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6143\n",
      "Epoch 325/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6228\n",
      "Epoch 326/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6226\n",
      "Epoch 327/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6166\n",
      "Epoch 328/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6164\n",
      "Epoch 329/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6127\n",
      "Epoch 330/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6126\n",
      "Epoch 331/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6171\n",
      "Epoch 332/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6128\n",
      "Epoch 333/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6261\n",
      "Epoch 334/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6220\n",
      "Epoch 335/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6211\n",
      "Epoch 336/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6064\n",
      "Epoch 337/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6166\n",
      "Epoch 338/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6128\n",
      "Epoch 339/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6094\n",
      "Epoch 340/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6073\n",
      "Epoch 341/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6084\n",
      "Epoch 342/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6133\n",
      "Epoch 343/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6073\n",
      "Epoch 344/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6130\n",
      "Epoch 345/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6104\n",
      "Epoch 346/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6090\n",
      "Epoch 347/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6024\n",
      "Epoch 348/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6118\n",
      "Epoch 349/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6057\n",
      "Epoch 350/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6239\n",
      "Epoch 351/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6156\n",
      "Epoch 352/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6057\n",
      "Epoch 353/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6004\n",
      "Epoch 354/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6000\n",
      "Epoch 355/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6023\n",
      "Epoch 356/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5961\n",
      "Epoch 357/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6028\n",
      "Epoch 358/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6016\n",
      "Epoch 359/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5975\n",
      "Epoch 360/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6019\n",
      "Epoch 361/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6033\n",
      "Epoch 362/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5993\n",
      "Epoch 363/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5991\n",
      "Epoch 364/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5971\n",
      "Epoch 365/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5918\n",
      "Epoch 366/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5950\n",
      "Epoch 367/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5971\n",
      "Epoch 368/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.6185\n",
      "Epoch 369/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6143\n",
      "Epoch 370/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5980\n",
      "Epoch 371/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5935\n",
      "Epoch 372/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5848\n",
      "Epoch 373/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5879\n",
      "Epoch 374/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5934\n",
      "Epoch 375/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5904\n",
      "Epoch 376/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5920\n",
      "Epoch 377/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5884\n",
      "Epoch 378/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5925\n",
      "Epoch 379/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6027\n",
      "Epoch 380/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6011\n",
      "Epoch 381/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5861\n",
      "Epoch 382/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5801\n",
      "Epoch 383/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5921\n",
      "Epoch 384/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5928\n",
      "Epoch 385/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5966\n",
      "Epoch 386/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5905\n",
      "Epoch 387/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5893\n",
      "Epoch 388/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5828\n",
      "Epoch 389/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5869\n",
      "Epoch 390/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5852\n",
      "Epoch 391/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.6108\n",
      "Epoch 392/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5796\n",
      "Epoch 393/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5791\n",
      "Epoch 394/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5822\n",
      "Epoch 395/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5807\n",
      "Epoch 396/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5937\n",
      "Epoch 397/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5895\n",
      "Epoch 398/400\n",
      "150/150 [==============================] - 7s 45ms/step - loss: 1.5779\n",
      "Epoch 399/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5788\n",
      "Epoch 400/400\n",
      "150/150 [==============================] - 7s 46ms/step - loss: 1.5804\n"
     ]
    }
   ],
   "source": [
    "for x, y in ds:\n",
    "    history = model.fit(x, y, steps_per_epoch=150, epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "s2Nm6UP7e2jz",
    "outputId": "2096eedd-43e5-42c9-820c-0d099ef30d0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    credentials=None\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "id": "Z5I0r55eZf6J",
    "outputId": "ff7dde97-1796-4f87-e462-3f4879ea141c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    }
   ],
   "source": [
    "model_num = params['version']\n",
    "model_path = 'image_caption_model_v{}.h5'.format(model_num)\n",
    "model.save(model_path)\n",
    "model_bucket = client.bucket('jh_hateful_memes')\n",
    "blob = model_bucket.blob(model_path)\n",
    "blob.upload_from_filename(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ll0ab_UfVlvi"
   },
   "outputs": [],
   "source": [
    "def get_image_captions(params, images):\n",
    "    '''\n",
    "    creates captions to a group of images\n",
    "    \n",
    "    args:\n",
    "        params: dictionary with at least the following keys:\n",
    "            caption_text_input_length: int, length of captions\n",
    "            tokenizer_start_index: int, value to signal start of caption\n",
    "            tokenizer_end_index: int, value to signal end of caption\n",
    "            \n",
    "        images: tensor, dtype: tf.float32 shaped (None, 299, 299, 3) None is the \n",
    "        number of images, each image should be normalized to have\n",
    "        pixel values of -1 to 1. Images to be captioned\n",
    "\n",
    "            \n",
    "    returns:\n",
    "        captions: tensor, dtype float, shaped \n",
    "        (None, params['caption_text_input_length'])None is the number of \n",
    "        images, image caption sequences\n",
    "    '''\n",
    "    num_images = len(images)\n",
    "    caption_len = params['text_input_length']\n",
    "    caption_end_index = params['tokenizer_end_index']\n",
    "\n",
    "    @tf.function\n",
    "    def get_capt(img, txt):\n",
    "        def caption_step(image_, text_):\n",
    "            '''\n",
    "            evaluate model here\n",
    "            '''\n",
    "            txt_ = tf.expand_dims(text_, axis=0)\n",
    "            pred = model((image_, txt_))\n",
    "\n",
    "\n",
    "            return pred\n",
    "        result = strategy.run(caption_step, args=(img, txt))\n",
    "        return result\n",
    "\n",
    "    \n",
    "    captions = list()\n",
    "    for image in range(num_images):\n",
    "        img = images[image]\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        txt_input = np.zeros((caption_len))\n",
    "        result = params['tokenizer_start_index']\n",
    "        for idx in range(caption_len):\n",
    "            txt_input[idx] = result\n",
    "            # with tf.device('/TPU:0'):\n",
    "            #     result = caption_step(img, txt_input)\n",
    "                # result = strategy.run(caption_step, args=(img, txt_input))\n",
    "            result = get_capt(img, txt_input)\n",
    "            result = result.numpy()[0] # result.values[0].numpy()[0]\n",
    "            result = tf.argmax(result, axis=0)\n",
    "            if result == caption_end_index:\n",
    "                break\n",
    "        captions.append(txt_input)\n",
    "    captions = tf.convert_to_tensor(captions)\n",
    "    return captions\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IDjhW_VF9HfO"
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    # plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "fVb6NnhPF6FS",
    "outputId": "6e40ef9d-b361-4115-c1e0-7be002006794"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss', 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jZc8L4MGe2j8",
    "outputId": "903317cd-b59b-4292-df42-0e3517145007"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5779247283935547"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6oYiyR_MIsr8"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "image_caption_model_draft.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
