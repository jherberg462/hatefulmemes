{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qJiMk2hxVVdH"
   },
   "outputs": [],
   "source": [
    "#download glove model from http://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip and\n",
    "#upload to bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "Iy1dZ-XUJHsF",
    "outputId": "8f30ec6d-6b06-4277-d6d7-82c42aa7a18d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "#set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow.random import set_seed\n",
    "set_seed(1)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#machine learning\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#accessing files\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#display charts/images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#don't need\n",
    "# from tensorflow.python.keras.preprocessing import sequence\n",
    "# from tensorflow.python.keras.preprocessing import text\n",
    "# import tensorflow_hub as hub\n",
    "\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ig0i-YXvJHsO"
   },
   "outputs": [],
   "source": [
    "params={\n",
    "    'image_size': [256, 256],\n",
    "    'vocab_size': 10000,\n",
    "    'text_input_length': 49,\n",
    "    'nodes': 256,\n",
    "    'tokenizer_start_index': 58, #index of tokenizer to signal sequence start\n",
    "    'tokenizer_end_index': 57,\n",
    "    'epochs': 5000,\n",
    "    'version': 4,\n",
    "    'embedding_dim': 300,\n",
    "    'ds_size': 801592\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-0QY626PJHsU"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "k3pADpk0JHsa"
   },
   "outputs": [],
   "source": [
    "training_bucket = 'gs://kds-ee517193eb9b1e4c46074f9961706f2509229d629f014905319a5517'\n",
    "glove_bucket = 'gs://kds-50159a18330aff39cf7ee2218221b8f222e6c9cfbda79e30fbe7a5eb'\n",
    "tfrecords = tf.io.gfile.glob(training_bucket + '/*tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XOOAMRQe7Nob",
    "outputId": "c7fee549-be3e-4347-f0c6-fe4d82e8a200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gs://kds-50159a18330aff39cf7ee2218221b8f222e6c9cfbda79e30fbe7a5eb/glove.840B.300d.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.io.gfile.glob(glove_bucket + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 768
    },
    "id": "6t9Kv3FyJHse",
    "outputId": "f3ce38e9-e6a6-4e63-80bd-2d97e9553cba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.49.108.218:8470\n",
      "INFO:tensorflow:Initializing the TPU system: grpc://10.49.108.218:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.49.108.218:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n",
      "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "arYwtpLjJHsi"
   },
   "outputs": [],
   "source": [
    "def decode_example(example):\n",
    "    '''\n",
    "    decodes single tfexample from TFrecord file\n",
    "    '''\n",
    "    features = {'text': tf.io.FixedLenFeature([], tf.string),\n",
    "                'inception': tf.io.FixedLenFeature([], tf.string), #can also be vgg\n",
    "                'y': tf.io.FixedLenFeature([], tf.string)}\n",
    "    single_example = tf.io.parse_single_example(example, features)\n",
    "    \n",
    "    text = tf.io.parse_tensor(single_example['text'], out_type=tf.int32)\n",
    "    text = tf.cast(text, tf.float32)\n",
    "    image_features = tf.io.parse_tensor(single_example['inception'], out_type=tf.float32)\n",
    "    y_value = tf.io.parse_tensor(single_example['y'], out_type=tf.int32)\n",
    "    y_value = tf.expand_dims(y_value, axis=0)\n",
    "\n",
    "    return (image_features, text), y_value\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HVGvXnmBJHsk"
   },
   "outputs": [],
   "source": [
    "def create_ds(files, params):\n",
    "    '''\n",
    "    function to create dataset for training/validation\n",
    "    \n",
    "    args:\n",
    "        files: list of str, filepaths of TFrecord files to be used in DS\n",
    "        params: dict with the following keys:\n",
    "            batch_size: int, batch size of training/validation step\n",
    "            examples_per_file: int, number of examples in each TFrecord file\n",
    "        train, bool, default True, indicator if the DS is for training\n",
    "        test_examples, int: default 1000 number of examples in test dataset\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images, text and labels\n",
    "            output of ds is: (text, image), label\n",
    "        ds_batches: int, number of steps in each epoch based on the batch_size\n",
    "    '''\n",
    "#     batch_size = 801592\n",
    "    batch_size = params['ds_size']\n",
    "\n",
    "    ds = tf.data.TFRecordDataset(filenames = files)\n",
    "    ds = ds.map(decode_example, \n",
    "                num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    ds = ds.batch(batch_size, drop_remainder=True)\n",
    "\n",
    "#     ds = ds.cache() \n",
    "    \n",
    "    return ds\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NKHCPu3cZf57"
   },
   "outputs": [],
   "source": [
    "def download_file(bucket, file_name):\n",
    "    '''\n",
    "    downloads a file from a public GCS bucket into working directory\n",
    "\n",
    "    args:\n",
    "        bucket: str, name of bucket to download file from\n",
    "        file_name: str, file name to download\n",
    "    returns: None\n",
    "    \n",
    "    '''\n",
    "    file_path = tf.io.gfile.glob(bucket + '/' + file_name)[0]\n",
    "    tf.io.gfile.copy(file_path, file_name)\n",
    "\n",
    "def create_tokenizer_from_filename(file_name,\n",
    "                                  bucket=None):\n",
    "    '''\n",
    "    creates tf.keras.preprocessing.text.tokenizer from a \n",
    "    json config file in current working directory\n",
    "    args:\n",
    "        file_name: str, filename where config json file is located\n",
    "        bucket, str, default None, name of GCS bucket with an object with the\n",
    "            same file name as glove_file, if an arg\n",
    "            is passed, function will first check if file_name exists in current\n",
    "            directory, and if not, will download an object located at file_name\n",
    "            in the bucket passed into bucket arg\n",
    "    returns:\n",
    "        tokenizer object\n",
    "    '''\n",
    "    if bucket:\n",
    "        if not os.path.isfile(file_name):\n",
    "            download_file(bucket,file_name)\n",
    "    with open(file_name) as file:\n",
    "        open_file = json.load(file)\n",
    "        tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(open_file)\n",
    "    return tokenizer\n",
    "\n",
    "def get_embedding_weights_from_tokenizer_glove(glove_file,\n",
    "                                              tokenizer,\n",
    "                                              embedding_dim,\n",
    "                                              bucket=None,\n",
    "                                              ):\n",
    "    '''\n",
    "    gets the weights to use in an embedding layer from a pretained\n",
    "    model based on the tokenizer used to create sequences that will\n",
    "    be passed into embedding layer\n",
    "    \n",
    "    args:\n",
    "        glove_file: str, path of pretrained model from current directory\n",
    "        tokenizer: tf.keras.preprocessing.text.tokenizer object, tokenizer\n",
    "            that was used to create sequences\n",
    "        embedding_dim: int, output_dim of embedding layer of pre-trained model\n",
    "        bucket, str, default None, name of GCS bucket with an object with the\n",
    "            same file name as glove_file, if an arg\n",
    "            is passed, function will first check if glove_file exists in current\n",
    "            directory, and if not, will download an object located at glove_file\n",
    "            in the bucket passed into bucket arg\n",
    "    returns: \n",
    "        embedding_weights: numpy array, shaped* (vocab_size, embedding_dim)\n",
    "            weights that can be used for embedding layer\n",
    "            *vocab_size = tokenizer.num_words which is the number of words in\n",
    "            the tokenizer vocabulary\n",
    "        \n",
    "    '''\n",
    "    if bucket:\n",
    "        if not os.path.isfile(glove_file):\n",
    "            download_file(bucket, glove_file)\n",
    "    word_values = dict()\n",
    "    file = open(glove_file, encoding='utf-8')\n",
    "    \n",
    "    for line in file:\n",
    "        coeff = line.split()\n",
    "        word = coeff[0]\n",
    "        coefficients = np.asarray(coeff[-300:], dtype='float32')\n",
    "        word_values[word] = coefficients\n",
    "    file.close()\n",
    "    vocab_size = tokenizer.num_words\n",
    "    embedding_weights = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        if idx < vocab_size:\n",
    "            word_embedding_values = word_values.get(word)\n",
    "            if word_embedding_values is not None:\n",
    "                embedding_weights[idx] = word_embedding_values\n",
    "    \n",
    "    return embedding_weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kx474nk2JHsm"
   },
   "outputs": [],
   "source": [
    "ds = create_ds(tfrecords, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NKb5yx6PJHsr"
   },
   "outputs": [],
   "source": [
    "def create_model(params, embedding_weights=None):\n",
    "    '''\n",
    "    creates model to caption images\n",
    "    '''\n",
    "    vocab_size = params['vocab_size']\n",
    "    txt_input_length = params['text_input_length']\n",
    "    nodes = params['nodes']\n",
    "    embedding_dim = params['embedding_dim']\n",
    "\n",
    "    image_feature_inp = layers.Input((2048,), name='features_input')\n",
    "    features = layers.Dropout(0.5)(image_feature_inp)\n",
    "    features = layers.Dense(nodes)(features)\n",
    "    features = layers.ReLU()(features)\n",
    "    \n",
    "    txt_inp = layers.Input((txt_input_length,), name='text_input')\n",
    "    embedding = layers.Embedding(vocab_size, embedding_dim, mask_zero=True)(txt_inp)\n",
    "    embedding = layers.Dropout(0.5)(embedding)\n",
    "    sequences = layers.LSTM(nodes)(embedding)\n",
    "\n",
    "    decoder = layers.Add()([features, sequences]) # Concatenate - try\n",
    "    decoder = layers.Dense(nodes, activation=None)(decoder)\n",
    "    decoder = layers.ReLU()(decoder)\n",
    "    output = layers.Dense(vocab_size, activation='softmax')(decoder)\n",
    "    model = keras.Model([image_feature_inp, txt_inp], output)\n",
    "    model.layers[3].set_weights([embedding_weights])\n",
    "    model.layers[3].trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-8DlDjMDZf6A"
   },
   "outputs": [],
   "source": [
    "tokenizer = create_tokenizer_from_filename('coco_tokenizer.json', \n",
    "                                           training_bucket)\n",
    "embedding_weights = get_embedding_weights_from_tokenizer_glove('glove.840B.300d.txt',\n",
    "                                                               tokenizer,\n",
    "                                                               300,\n",
    "                                                               glove_bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "bVGtPCLSJHst"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(params, embedding_weights) #embedding_weights\n",
    "    model.compile(optimizer='adam', loss='SparseCategoricalCrossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "l-W5mrRkgs6f",
    "outputId": "a374827c-85a8-436a-8359-0fd47c504abb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f4c98840da0>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "KnC_gdymcvT7",
    "outputId": "72467fca-d2ba-4c1f-8859-73716a49383d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:601: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Iterator.get_next_as_optional()` instead.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                patience=50,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "for input_data, ground_truth in ds:\n",
    "    history = model.fit(input_data, ground_truth, steps_per_epoch=150, epochs=5000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "s2Nm6UP7e2jz",
    "outputId": "bcc18ab9-bc26-4379-e0c0-2a842d126ecf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()\n",
    "    credentials=None\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "\n",
    "\n",
    "    from google.oauth2 import service_account\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "        '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Z5I0r55eZf6J"
   },
   "outputs": [],
   "source": [
    "model_num = params['version']\n",
    "model_path = 'image_caption_model_v{}.h5'.format(model_num)\n",
    "model.save(model_path)\n",
    "model_bucket = client.bucket('jh_hateful_memes')\n",
    "blob = model_bucket.blob(model_path)\n",
    "blob.upload_from_filename(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ll0ab_UfVlvi"
   },
   "outputs": [],
   "source": [
    "def get_image_captions(params, images):\n",
    "    '''\n",
    "    creates captions to a group of images\n",
    "    \n",
    "    args:\n",
    "        params: dictionary with at least the following keys:\n",
    "            caption_text_input_length: int, length of captions\n",
    "            tokenizer_start_index: int, value to signal start of caption\n",
    "            tokenizer_end_index: int, value to signal end of caption\n",
    "            \n",
    "        images: tensor, dtype: tf.float32 shaped (None, 299, 299, 3) None is the \n",
    "        number of images, each image should be normalized to have\n",
    "        pixel values of -1 to 1. Images to be captioned\n",
    "\n",
    "            \n",
    "    returns:\n",
    "        captions: tensor, dtype float, shaped \n",
    "        (None, params['caption_text_input_length'])None is the number of \n",
    "        images, image caption sequences\n",
    "    '''\n",
    "    num_images = len(images)\n",
    "    caption_len = params['text_input_length']\n",
    "    caption_end_index = params['tokenizer_end_index']\n",
    "\n",
    "    @tf.function\n",
    "    def get_capt(img, txt):\n",
    "        def caption_step(image_, text_):\n",
    "            '''\n",
    "            evaluate model here\n",
    "            '''\n",
    "            txt_ = tf.expand_dims(text_, axis=0)\n",
    "            pred = model((image_, txt_))\n",
    "\n",
    "\n",
    "            return pred\n",
    "        result = strategy.run(caption_step, args=(img, txt))\n",
    "        return result\n",
    "\n",
    "    \n",
    "    captions = list()\n",
    "    for image in range(num_images):\n",
    "        img = images[image]\n",
    "        img = tf.expand_dims(img, axis=0)\n",
    "        txt_input = np.zeros((caption_len))\n",
    "        result = params['tokenizer_start_index']\n",
    "        for idx in range(caption_len):\n",
    "            txt_input[idx] = result\n",
    "            # with tf.device('/TPU:0'):\n",
    "            #     result = caption_step(img, txt_input)\n",
    "                # result = strategy.run(caption_step, args=(img, txt_input))\n",
    "            result = get_capt(img, txt_input)\n",
    "            result = result.numpy()[0] # result.values[0].numpy()[0]\n",
    "            result = tf.argmax(result, axis=0)\n",
    "            if result == caption_end_index:\n",
    "                break\n",
    "        captions.append(txt_input)\n",
    "    captions = tf.convert_to_tensor(captions)\n",
    "    return captions\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IDjhW_VF9HfO"
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    # plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fVb6NnhPF6FS",
    "outputId": "fedbb4a0-f407-4c18-e326-7ac3ffff5780"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEJCAYAAACZjSCSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3RdZb3u8e9vXbLSJuk16YWmtBSqWAotEDiw2VSEg1wFFVTcm6uXDpWtcPTgls3eimz34ShneNt4RA7gKIpSRHBX5GIVFKpQSEtLaQu0lAIpvSRpmyZpc1lZv/PHmqlZ6UpJm861ksznM8YamWvOd835vhlJnrzznfOd5u6IiEh0xYpdARERKS4FgYhIxCkIREQiTkEgIhJxCgIRkYhTEIiIRFyoQWBmG81slZmtMLPaPNvNzH5oZuvN7CUzOyHM+oiIyL4SBTjGB9y9oY9t5wEzg9d/A34cfBURkQIpRBDsz8XAvZ69q+05MxtjZpPdfXNfH6isrPTp06cXrIIiIsPBsmXLGty9Kt+2sIPAgd+bmQM/cfc7e22fArzd431dsC4nCMxsPjAf4PDDD6e2dp+zTCIish9m9mZf28IeLP57dz+B7Cmga81s3sHsxN3vdPcad6+pqsobaCIicpBCDQJ33xR83QY8DJzcq8gmYGqP99XBOhERKZDQgsDMysysonsZ+CDwcq9ii4Arg6uHTgGa9jc+ICIih16YYwQTgYfNrPs4v3D3x83scwDufgfwKHA+sB7YDVwTYn1ERPbq7Oykrq6Otra2YlflkCotLaW6uppkMtnvz4QWBO6+AZiTZ/0dPZYduDasOoiI9KWuro6KigqmT59O8A/rkOfuNDY2UldXxxFHHNHvz+nOYhGJpLa2NsaPHz9sQgDAzBg/fvwB93IUBCISWcMpBLodTJsiEwSvbW3mu79/lYaW9mJXRURkUIlMEKzb2sIPn1zP9taOYldFRASA8vLyYlcBiFAQdNMjmkVEckUmCIbhqUARGSbcnRtuuIHZs2dz7LHHsnDhQgA2b97MvHnzmDt3LrNnz+aZZ56hq6uLq6++em/Z733vewM+frEnnRMRKbpv/nY1a97ZdUj3OeuwUXzjQ8f0q+xDDz3EihUrWLlyJQ0NDZx00knMmzePX/ziF5xzzjncdNNNdHV1sXv3blasWMGmTZt4+eXs/bk7d+4ccF0j0yPo5ujckIgMLkuWLOGTn/wk8XiciRMn8v73v58XXniBk046iZ/+9KfcfPPNrFq1ioqKCmbMmMGGDRv44he/yOOPP86oUaMGfPzI9Ah0ZkhE+tLf/9wLbd68eTz99NP87ne/4+qrr+bLX/4yV155JStXruSJJ57gjjvu4IEHHuCee+4Z0HGi1yNQh0BEBpnTTz+dhQsX0tXVRX19PU8//TQnn3wyb775JhMnTuSzn/0sn/nMZ1i+fDkNDQ1kMhkuueQSvvWtb7F8+fIBHz86PQJ1CURkkPrIRz7Cs88+y5w5czAzvvOd7zBp0iQWLFjAbbfdRjKZpLy8nHvvvZdNmzZxzTXXkMlkALj11lsHfPzIBIGIyGDT0tICZO8Gvu2227jttttytl911VVcddVV+3zuUPQCetKpIRGRiItQEOjckIhIPhEKgixdPioi3XwYniI4mDZFJgg0WCwiPZWWltLY2DiswqD7eQSlpaUH9DkNFotIJFVXV1NXV0d9fX2xq3JIdT+h7EBELgiGUfiLyAAkk8kDeorXcBadU0PFroCIyCAVmSAQEZH8IhMEw/GRdCIih0LoQWBmcTN70cweybPtajOrN7MVweszYddHYwQiIrkKMVh8HbAW6Guu1IXu/k9hV0L9ARGR/ELtEZhZNXABcFeYxxERkYMX9qmh7wNfBTL7KXOJmb1kZg+a2dR8BcxsvpnVmlntQK/51Z3FIiK5QgsCM7sQ2Obuy/ZT7LfAdHc/DlgMLMhXyN3vdPcad6+pqqo6yPoc1MdERIa9MHsEpwEXmdlG4H7gTDP7ec8C7t7o7u3B27uAE0OsT3DMsI8gIjK0hBYE7n6ju1e7+3TgMuBJd7+8Zxkzm9zj7UVkB5VDoR6BiEh+BZ9iwsxuAWrdfRHwJTO7CEgD24GrC10fEZGoK0gQuPufgD8Fy1/vsf5G4MZC1GHvMQt5MBGRISA6dxbrTgIRkbwiEwTdhtPc4yIih0J0gkAdAhGRvKITBCIiklfkgkAnhkREckUmCHRmSEQkv8gEQTeNFYuI5IpMEOjBNCIi+UUmCP5GXQIRkZ4iEwTqD4iI5BeZIBARkfwiFwQaLBYRyRWZINBYsYhIfpEJgm7qEIiI5IpMEGj2URGR/CITBCIikl/kgkCDxSIiuSITBBosFhHJLzJB0E0PphERyRWZIFCHQEQkv8gEgYiI5Bd6EJhZ3MxeNLNH8mxLmdlCM1tvZkvNbHrY9dGJIRGRXIXoEVwHrO1j26eBHe5+FPA94Nuh1ULnhkRE8go1CMysGrgAuKuPIhcDC4LlB4GzLOQHB2isWEQkV9g9gu8DXwUyfWyfArwN4O5poAkY37uQmc03s1ozq62vrz+oiujOYhGR/EILAjO7ENjm7ssGui93v9Pda9y9pqqqamD70iiBiEiOMHsEpwEXmdlG4H7gTDP7ea8ym4CpAGaWAEYDjWFURjeUiYjkF1oQuPuN7l7t7tOBy4An3f3yXsUWAVcFy5cGZfQvu4hIASUKfUAzuwWodfdFwN3Az8xsPbCdbGCESzEjIpKjIEHg7n8C/hQsf73H+jbgY4Wog84MiYjkF7k7i9UhEBHJFZkgCPn2BBGRISsyQSAiIvlFLgh0TZKISK7IBIHODImI5BeZIOimO4tFRHJFJgjUIRARyS8yQSAiIvlFLgg0WCwikisyQaDBYhGR/CITBN3UIRARyRWhIFCXQEQknwgFgYiI5BO5INDjDkREckUmCDRYLCKSX2SCoJv6AyIiuSITBOoQiIjkF5kg2EtdAhGRHJEJAj2YRkQkv8gEgYiI5Be5INA01CIiuUILAjMrNbPnzWylma02s2/mKXO1mdWb2Yrg9ZnQ6hPWjkVEhrhEiPtuB8509xYzSwJLzOwxd3+uV7mF7v5PIdYjh+4nExHJFVoQePYW3pbgbTJ4Fe3PsMaKRUTyC3WMwMziZrYC2AYsdveleYpdYmYvmdmDZja1j/3MN7NaM6utr68Ps8oiIpETahC4e5e7zwWqgZPNbHavIr8Fprv7ccBiYEEf+7nT3WvcvaaqqmqAdRrQx0VEhp2CXDXk7juBp4Bze61vdPf24O1dwIlh1cE0XCwikleYVw1VmdmYYHkEcDbwSq8yk3u8vQhYG1Z9uqlDICKSK8yrhiYDC8wsTjZwHnD3R8zsFqDW3RcBXzKzi4A0sB24OqzKaLBYRCS/MK8aegk4Ps/6r/dYvhG4Maw6iIjIu4vencUaLRYRyRG5IBARkVyRCwL1B0REckUmCDRYLCKSX2SCoJuGCEREckUmCHRDmYhIfv0KAjO7zsxGWdbdZrbczD4YduVERCR8/e0RfMrddwEfBMYCVwD/O7RahUrnhkREeupvEHSfVzkf+Jm7r2aIPetFg8UiIvn1NwiWmdnvyQbBE2ZWAWTCq1Z4NFgsIpKrv1NMfBqYC2xw991mNg64JrxqHXrqEYiI5NffHsGpwKvuvtPMLgf+FWgKr1oiIlIo/Q2CHwO7zWwO8BXgdeDe0GoVIp0ZEhHJ1d8gSAfPIL4YuN3dfwRUhFetQ0/3EYiI5NffMYJmM7uR7GWjp5tZjOzD6IccDRaLiOTqb4/gE0A72fsJtpB9BvFtodUqBBosFhHJr19BEPzxvw8YbWYXAm3uPiTHCEREJFd/p5j4OPA88DHg48BSM7s0zIqFxTVcLCKSo79jBDcBJ7n7Nsg+mB74A/BgWBU71HRmSEQkv/6OEcS6QyDQeACfHVQ0WCwikqu/PYLHzewJ4JfB+08Aj4ZTpXBosFhEJL9+BYG732BmlwCnBavudPeH9/cZMysFngZSwXEedPdv9CqTIntj2olkexmfcPeNB9SCA6QOgYhIrv72CHD3XwO/PoB9twNnunuLmSWBJWb2mLs/16PMp4Ed7n6UmV0GfJtsbyME6hKIiOSz3yAws2by/xNtgLv7qL4+G9yJ3BK8TQav3vu6GLg5WH4QuN3MLPisiIgUwH6DwN0HNI2EmcWBZcBRwI/cfWmvIlOAt4Njpc2sCRgPNPTaz3xgPsDhhx8+kCqhjBERyRXqlT/u3uXuc8neiXyymc0+yP3c6e417l5TVVV1UHXRYLGISH4FuQTU3XcCTwHn9tq0CZgKYGYJYDTZQWMRESmQ0ILAzKrMbEywPAI4G3ilV7FFwFXB8qXAk2GND8SDLkFGp4ZERHL0+6qhgzAZWBCME8SAB9z9ETO7Bah190XA3cDPzGw9sB24LKzKxGPZIEh3KQhERHoKLQjc/SXg+Dzrv95juY3s/EWhi8XUIxARyWdIThNxMLpPDXVlilwREZFBJjpBEOsOAiWBiEhPEQwCnRoSEekpOkHQfWpIOSAikiM6QRAPBovVIxARyRGdIAh6BGkFgYhIjsgEQSxoqS4fFRHJFZkgSARJoMFiEZFckQmC4KIhnRoSEeklMkFgZsRMg8UiIr1FJggge3qoS2MEIiI5IhUEsZjGCEREeotUEMTNFAQiIr1EKwhiCgIRkd4UBCIiERe9INBgsYhIjkgFQcxMl4+KiPQSqSBIxEw3lImI9BKpIIjF1CMQEektUkGgMQIRkX1FKggSMSOtJ9OIiOQILQjMbKqZPWVma8xstZldl6fMGWbWZGYrgtfXw6oPQEkiTntazywWEekpEeK+08BX3H25mVUAy8xssbuv6VXuGXe/MMR67JVKxGhPdxXiUCIiQ0ZoPQJ33+zuy4PlZmAtMCWs4/VHKhGjQz0CEZEcBRkjMLPpwPHA0jybTzWzlWb2mJkd08fn55tZrZnV1tfXH3Q9ShIxnRoSEekl9CAws3Lg18D17r6r1+blwDR3nwP8J/CbfPtw9zvdvcbda6qqqg66LimNEYiI7CPUIDCzJNkQuM/dH+q93d13uXtLsPwokDSzyrDqk0rG6NAYgYhIjjCvGjLgbmCtu3+3jzKTgnKY2clBfRrDqlMqrlNDIiK9hXnV0GnAFcAqM1sRrPsX4HAAd78DuBT4vJmlgT3AZe7h3fGVSioIRER6Cy0I3H0JYO9S5nbg9rDq0FsqEddVQyIivUTqzuIS3UcgIrKPSAVBKrh8NMSzTyIiQ06kgqA0GccdOrp0ekhEpFukgqCsJA5Aa7tOD4mIdItUEJSXJgFoaUsXuSYiIoNHtIIglb1Iqrm9s8g1EREZPCIVBBWl2SBQj0BE5G8iFQTdPYKWdgWBiEi3aAVBqYJARKS3SAVBhXoEIiL7iFYQBFcN7dytwWIRkW6RCoIRJXHKUwkaWtqLXRURkUEjUkEAUFleQkNLR7GrISIyaEQuCKoqUtQ3txW7GiIig0Ykg0A9AhGRv4lcEFSWp6hv1hiBiEi3yAVBVXmKpj2dtHVq4jkREYhgEFSPGwFA3Y7dRa6JiMjgELkgmFFZDsDr9a1FromIyOAQvSCoKgNgg4JARASIYBBUlCapqkixob6l2FURERkUQgsCM5tqZk+Z2RozW21m1+UpY2b2QzNbb2YvmdkJYdWnpyOrynhtm4JARATC7RGkga+4+yzgFOBaM5vVq8x5wMzgNR/4cYj12WtO9RjWvrNLVw6JiBBiELj7ZndfHiw3A2uBKb2KXQzc61nPAWPMbHJYdep24rSxdHRlWLWpKexDiYgMegUZIzCz6cDxwNJem6YAb/d4X8e+YYGZzTezWjOrra+vH3B9aqaPA+DZ1xsHvC8RkaEu9CAws3Lg18D17r7rYPbh7ne6e42711RVVQ24TuPKSjjh8DE8sXrLgPclIjLUhRoEZpYkGwL3uftDeYpsAqb2eF8drAvdebMns/qdXbyuq4dEJOLCvGrIgLuBte7+3T6KLQKuDK4eOgVocvfNYdWppw/NOQwzuP/5twpxOBGRQSvMHsFpwBXAmWa2Inidb2afM7PPBWUeBTYA64H/B3whxPrkmDS6lHNmTeK+pW/R3KYnlolIdCXC2rG7LwHsXco4cG1YdXg3137gKB5fvYX/9ehabv3occWqhohIUUXuzuKejq0ezekzK/lVbR1vNGjKCRGJpkgHAcD/+dgcRpbEueTHf6W1PV3s6oiIFFzkg2DiqFJu/ehxbG/t4PqFK+jKeLGrJCJSUJEPAoALjpvMl86ayeI1W/nknc+xvVWPshSR6FAQBL589nv49w/P5vmN2znh3xezZF1DsaskIlIQCoIerjhlGjec814ALr97KdO/9jtNTCciw56CoJdrP3AUd11Zs/f90f/2OFfcvZTOrkwRayUiEh4FQR7/fdZE3rj1fE6fWQnAM+saOOk//sBP//IGTbt185mIDC+Wvadr6KipqfHa2tqCHS/dleE/Hl3L829sZ/U72Tnz4jHj4zXVfOGMo5g6bmTB6iIicrDMbJm71+TdpiDoH3fnxbd38tH/+9e822/+0CwuP2Uaibg6WSIy+CgIDrG2zi6uv38Fj+9nGuszj57ADy6bS0VpsoA1ExHJT0EQInfnlS3NnPeDZ4jHbJ8b0o6oLOOYw0bx6pZm3jd5FFecOo33TqpglAJCRApIQVBAXRnnyVe2cc+SNzhh2hjWbW3h5U1NvNPUtt/PffuSYzlx2ljGl6UYMzJJdhZvEZFDQ0EwCGxrbmPJugZe2LiDXz7/FrOnjOLlTX0/sG1GVRljR5YwsiTOsVNGU1GaZOzIJDMnllOWShAzY+aEcgWGiPSLgmAQc3fqm9vZ0NDKM+vq+cOabYwakaCyPMWzGxrZeYCXq86aPIpk3Fi1qYmMw9GTKrho7mFUjx3JeyaWM3NCBfGYwkMkahQEQ1xnV4b65nY2N7WxvbWD3658h0Ur3wnteGUlcdIZpz2dYcqYERw7ZTQTR6XYsbuTc2dPYvLoUipKE0wYVUoiZoxIxtUzERnkFAQR09qeZnPTHpasa+D5jdtJxGI8s66eslSC02dWsWbzLrY07WHrrvZDfuyxI7OD4LOnjOYv6xt4/3uqGD0iyW9WvMPpMyt5Zl0DV5wyjcVrtrK9tYPqsSO46YL3MSIZJ5mIsaejixlVZcRjRkc6Q1kqQUkixohknJiZejMiB0lBIP3m7qQzzuadbby6tZmSRIxnX2/kwWV1NLS0M2XMCDbt3JP3szGDyaNHUJqMMbIkwapNTQCUxGN0hDBFxzGHjaI0GScZN5LxGM/0mCjwo8dP4aEXN+3zmU+ddgS1b25nT0fX3lB5ZUszFaUJ5lSPoW7Hbua9p4r65nYqShNMG1/GaUdV0pXJsKstzYSKFDMqy0nEjUTMyHi23UDOsnpIMtgoCKToun/OdrWlyWScDQ0tLH1jO6lEnBMOH0NHOkNjaweL12zl1BnjSWecf3l4FSdOG8uWpjZGj0hSUZpg6RvbGVdWQmt7mhMOH5vtOXRl6OzKsKG+laY9nVSkEsRiRtOe4k4HUlWRor65Pe9lxd1KkzHaOjPMmjyKIyeUs2RdPTt2d3JEZRnpTIa3t+eG7mGjS3mnqY2ZE8pZt62Fs2dNZO7UMUwcVcrKt3fys+fe5Ljq0Vxw7GTiwfcgZsb48hJ2tHYyvXIkU8aMoDQZZ+uuNjIOR1SOJJWI09bZRXs6Q3s6g1k2wCeOKqUsFScZj5GMZ3tsqUSMmHpmQ46CQCLP3dkd9AKa9nTS3NZJ055O6pvbaU9naOvs4pUtzby9fTfHVY9hyfoGtu5qY0JFinOOmcQbDa3ct/QtAG44571kMk5jawebm/ZQt2MPjS0dbNnVxlETylm/rQWAs2dN5LWtzRw2egTPbmgsZvOL4t16giNL4hw+biR1O/bQEjwdsLK8hOa2NO3p/J877ajx/GV9I5XlJZx/7GTuffbNnO1nHT2BmRMr2NbcxqOrNvOh4w7jV8vq9m6fPn4kEypKGTUiSWt7mmc3NPL5M47ktyvf4agJ5fzp1Xpu/tAstja3c9yU0YxMJdjR2kHGnTEjk7R1Zvjr6w3MnFDBq1ubebOxlX84eRobG1s5afo4Wto7ae/8W5iOL0sxZWy2l5xKxGlsaae5Pc3EUaVkMk7Tnk4qy1OMHpGkPd2FYdS3tFM9dgQZd7oyTkkihjskYjagmQsUBCJDjLtjZrSnu3AHM9jd3kVLexp3KC9N8OqWZqoqSsg4dKQzNO3p5KlXtjFt/Eiqx42kflc7nZkM7Z0ZGlvbeWv7HqaNG8mUsSNIxIyHX9xEWSrB+cdOojPt/G7VZlKJGL9fs3VvPWZUlVESj9GVcSaNLt17+q1n4AGkEjFK4jHa0l10dmX/ppw4bSzL3tyx33bOqCxjx+4OdhzEZI5lJXFaO6I1Tfx1Z83kf5z9noP67P6CIDGgWu3/oPcAFwLb3H12nu1nAP8FvBGsesjdbwmrPiJDSfcYQyoR37sulYgztqxk7/tTjxy/z+dOO6qy38f4WM3UnPcfP2lqHyUHl+6QBGhpT5NKZIMq486IZBx3aO1IkwwCrLU9zcbG3YwsiVOSyJ7iqtuxm9Jk9nRYaTJOZzpDeWmCZ19v5Iz3TmBXWyepRCy4Yq+DZNyoLE+Rzjh/fq2e7a3trNvaQkdXhnOPmcQrW5opS8UZWZJg5+4OajfuYENDK2cePYG/O3I8ZakELW1pbn1sLRmH82ZPYsuuNl58aycA/3zu0Wxu2rNPD6eyPEVVRYr2zi7e3rGb902uCOV7GlqPwMzmAS3AvfsJgv/p7hceyH7VIxAROXD76xGENlWmuz8NbA9r/yIicmgUe87kU81spZk9ZmbH9FXIzOabWa2Z1dbX1xeyfiIiw14xg2A5MM3d5wD/Cfymr4Lufqe717h7TVVVVcEqKCISBUULAnff5e4twfKjQNLM+j/SJSIih0TRgsDMJlkw9G9mJwd1id7F1iIiRRbm5aO/BM4AKs2sDvgGkARw9zuAS4HPm1ka2ANc5kPtpgYRkWEgtCBw90++y/bbgdvDOr6IiPRPsa8aEhGRIhtyU0yYWT3w5rsWzK8SaHjXUsOL2hwNanM0DKTN09w972WXQy4IBsLMavu6s264UpujQW2OhrDarFNDIiIRpyAQEYm4qAXBncWuQBGozdGgNkdDKG2O1BiBiIjsK2o9AhER6UVBICIScZEJAjM718xeNbP1Zva1YtdnIMzsHjPbZmYv91g3zswWm9m64OvYYL2Z2Q+Ddr9kZif0+MxVQfl1ZnZVMdrSH2Y21cyeMrM1ZrbazK4L1g/nNpea2fPBNO2rzeybwfojzGxp0LaFZlYSrE8F79cH26f32NeNwfpXzeyc4rSo/8wsbmYvmtkjwfth3WYz22hmq8xshZnVBusK+7Pt7sP+BcSB14EZQAmwEphV7HoNoD3zgBOAl3us+w7wtWD5a8C3g+XzgccAA04BlgbrxwEbgq9jg+WxxW5bH+2dDJwQLFcArwGzhnmbDSgPlpPA0qAtD5CdlwvgDuDzwfIXgDuC5cuAhcHyrODnPQUcEfwexIvdvndp+5eBXwCPBO+HdZuBjUBlr3UF/dmOSo/gZGC9u29w9w7gfuDiItfpoHn+p79dDCwIlhcAH+6x/l7Peg4YY2aTgXOAxe6+3d13AIuBc8Ov/YFz983uvjxYbgbWAlMY3m12D6ZpJxsEScCBM4EHg/W929z9vXgQOCuY3fdi4H53b3f3N4D1ZH8fBiUzqwYuAO4K3hvDvM19KOjPdlSCYArwdo/3dcG64WSiu28OlrcAE4Plvto+JL8nQff/eLL/IQ/rNgenSFYA28j+Yr8O7HT3dFCkZ/33ti3Y3gSMZ4i1Gfg+8FUgE7wfz/BvswO/N7NlZjY/WFfQn+3QZh+V4nF3N7Nhd12wmZUDvwaud/dd2X/+soZjm929C5hrZmOAh4Gji1ylUJnZhcA2d19mZmcUuz4F9PfuvsnMJgCLzeyVnhsL8bMdlR7BJmBqj/fVwbrhZGvQRST4ui1Y31fbh9T3xMySZEPgPnd/KFg9rNvczd13Ak8Bp5I9FdD9D1zP+u9tW7B9NNkHPQ2lNp8GXGRmG8mevj0T+AHDu824+6bg6zaygX8yBf7ZjkoQvADMDK4+KCE7sLSoyHU61BYB3VcKXAX8V4/1VwZXG5wCNAVdzieAD5rZ2OCKhA8G6wad4Lzv3cBad/9uj03Duc1VQU8AMxsBnE12bOQpsg91gn3b3P29uBR40rOjiIuAy4IrbI4AZgLPF6YVB8bdb3T3anefTvZ39El3/0eGcZvNrMzMKrqXyf5Mvkyhf7aLPWJeqBfZ0fbXyJ5nvanY9RlgW34JbAY6yZ4L/DTZc6N/BNYBfwDGBWUN+FHQ7lVATY/9fIrsQNp64Jpit2s/7f17sudRXwJWBK/zh3mbjwNeDNr8MvD1YP0Msn/U1gO/AlLB+tLg/fpg+4we+7op+F68CpxX7Lb1s/1n8LerhoZtm4O2rQxeq7v/NhX6Z1tTTIiIRFxUTg2JiEgfFAQiIhGnIBARiTgFgYhIxCkIREQiTkEgUkBmdkb3rJoig4WCQEQk4hQEInmY2eWWfR7ACjP7STABXIuZfc+yzwf4o5lVBWXnmtlzwfzwD/eYO/4oM/uDZZ8psNzMjgx2X25mD5rZK2Z2n/WcNEmkCBQEIr2Y2fuATwCnuftcoAv4R6AMqHX3Y4A/A98IPnIv8M/ufhzZuz27198H/Mjd5wB/R/ZucMjOnno92XnzZ5CdY0ekaDT7qMi+zgJOBF4I/lkfQXbSrwywMCjzc+AhMxsNjHH3PwfrFwC/CuaPmeLuDwO4extAsL/n3b0ueL8CmA4sCb9ZIvkpCET2ZcACd78xZ6XZv/Uqd7Dzs7T3WO5Cv4dSZDo1JLKvPwKXBvPDdz8/dhrZ35fuWTD/AVji7k3ADjM7PVh/BfBnzz5Jrc7MPhzsI2VmIwvaCpF+0n8iIr24+xoz+1eyT42KkZ3l9VqgFTg52LaN7DgCZKcJviP4Q78BuCZYfwXwEzO7JdjHxwrYDJF+0+yjItcjMBoAAAA5SURBVP1kZi3uXl7seogcajo1JCISceoRiIhEnHoEIiIRpyAQEYk4BYGISMQpCEREIk5BICIScf8fU+VaHmZVZBYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('loss', 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "jZc8L4MGe2j8",
    "outputId": "f79eab54-edac-4b9c-e191-6aa0c668d4cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.553514003753662"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fckMXlLoe2j9"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "image_caption_model (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
