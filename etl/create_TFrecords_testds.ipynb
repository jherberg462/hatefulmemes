{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.preprocessing import text\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from google.cloud import storage\n",
    "\n",
    "#helper functions\n",
    "from helper_fn import load_jsonl_file, upload_TFrecord_gcs, get_imgBytestring_from_filePath, calc_idxs\n",
    "from features import int_feature, text_feature, imageString_feature\n",
    "from nlp_transform import transform_to_lemma, remove_stopwords, tokenize, create_tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "    '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_ds = load_jsonl_file('dev.jsonl')\n",
    "train_ds = load_jsonl_file('train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TFexample(dict_, tokenizer, padding):\n",
    "    '''\n",
    "    creates a TFexample with the following features:\n",
    "        image\n",
    "        label\n",
    "        id\n",
    "        text\n",
    "        text_lemma\n",
    "        text_lemma_no_stopwords\n",
    "        text_no_stopwords\n",
    "    \n",
    "    args:\n",
    "        dict_: dictionary with the following keys:\n",
    "            id: int, id of image\n",
    "            img: str, file path of image\n",
    "            label: int, indicator if meme is hateful or not\n",
    "            text: str, text on meme\n",
    "        tokenizer: keras.preprocessing.text.Tokenizer object that will be used to preprocess text\n",
    "        padding: int, length of each text vector. If text length is less, zeros will be added to \n",
    "        beginning, and if the text length is greater than padding, it will be truncated\n",
    "        \n",
    "    \n",
    "    returns: TFexample with above features\n",
    "    '''\n",
    "    \n",
    "    features = {\n",
    "        'image': imageString_feature(get_imgBytestring_from_filePath(dict_['img'])),\n",
    "#         'label': int_feature(dict_['label']),\n",
    "        'id': int_feature(dict_['id']),\n",
    "        'text': text_feature(tokenize(dict_['text'], tokenizer, padding)),\n",
    "        #add stopwords and lemons\n",
    "        'text_lemma' : text_feature(tokenize(transform_to_lemma(dict_['text']), tokenizer, padding)),\n",
    "        'text_lemma_no_stopwords' : text_feature(tokenize(transform_to_lemma(dict_['text'], remove_stop=True),\n",
    "                                                          tokenizer, padding)),\n",
    "        'text_no_stopwords' : text_feature( tokenize(remove_stopwords(dict_['text']), tokenizer,\n",
    "                                                     padding))\n",
    "        \n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TFrecord(meme_list, \n",
    "                    start_idx, end_idx,\n",
    "                    tokenizer, padding,\n",
    "                    tfr_file_num, ttl_tfr_files=10):\n",
    "    '''\n",
    "    creates a TFrecord file\n",
    "    \n",
    "    args:\n",
    "        meme_list: list\n",
    "    \n",
    "    \n",
    "    returns:\n",
    "        TFrecord_filepath, str, file path of newly created tfrecord file\n",
    "    '''\n",
    "    TFrecord_filepath = 'hatefulmemes_{}_of_{}.tfrecord'.format(tfr_file_num,\n",
    "                                                               ttl_tfr_files)\n",
    "    with tf.io.TFRecordWriter(TFrecord_filepath) as writer:\n",
    "        for idx in range(start_idx, end_idx + 1):\n",
    "            TFexample = create_TFexample(meme_list[idx], tokenizer, padding)\n",
    "            writer.write(TFexample.SerializeToString())\n",
    "    \n",
    "    return TFrecord_filepath\n",
    "    ###continue working on documentation\n",
    "    #move to helper_fn once documentation is complete (import tensorflow as tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ds_path, client, bucket, num_splits=10, top_words=20000, padding=41, preprocess=transform_to_lemma):\n",
    "    '''\n",
    "    creates all TFrecord files\n",
    "    '''\n",
    "    ds = load_jsonl_file(ds_path)\n",
    "    json_file_name = 'tokenizer.json'\n",
    "    tokenizer_json = load_jsonl_file(json_file_name)\n",
    "    tokenizer = text.tokenizer_from_json(tokenizer_json[0])\n",
    "    startEnd_idxs = calc_idxs(ds, num_splits)\n",
    "    file_num = 1\n",
    "    for startIdx, endIdx in startEnd_idxs:\n",
    "        TFrecord_path = create_TFrecord(ds, startIdx, endIdx,\n",
    "                                        tokenizer, padding,\n",
    "                                        file_num, num_splits)\n",
    "        upload_TFrecord_gcs(TFrecord_path, client, bucket)\n",
    "        file_num +=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main('dev.jsonl', client, 'jh_hateful_memes_dev', padding=41, top_words=30000)#padding - 41 for dev, 58 for train\n",
    "main('test.jsonl', client, 'jh_hateful_memes_test', padding=58, num_splits=2)#padding - 41 for dev, 58 for train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
