{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download 2014 train images and annotations from https://cocodataset.org/#download unzip, \n",
    "#and place files in same folder as this notebook/script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.preprocessing import sequence\n",
    "from tensorflow.python.keras.preprocessing import text\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "#helper functions\n",
    "from helper_fn import load_jsonl_file, upload_TFrecord_gcs, calc_idxs, get_imgBytestring_from_filePath\n",
    "from features import int_feature, text_feature, imageString_feature\n",
    "from nlp_transform import tokenize, create_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.oauth2 import service_account\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_file( #file location of GCS private key\n",
    "    '/Users/jeremiahherberg/Downloads/hateful-memes-af65c70c1b79.json')\n",
    "\n",
    "client = storage.Client(project='hateful-memes', credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_jsonl_file('captions_train2014.json')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/',\n",
       "  'id': 1,\n",
       "  'name': 'Attribution-NonCommercial-ShareAlike License'},\n",
       " {'url': 'http://creativecommons.org/licenses/by-nc/2.0/',\n",
       "  'id': 2,\n",
       "  'name': 'Attribution-NonCommercial License'},\n",
       " {'url': 'http://creativecommons.org/licenses/by-nc-nd/2.0/',\n",
       "  'id': 3,\n",
       "  'name': 'Attribution-NonCommercial-NoDerivs License'},\n",
       " {'url': 'http://creativecommons.org/licenses/by/2.0/',\n",
       "  'id': 4,\n",
       "  'name': 'Attribution License'},\n",
       " {'url': 'http://creativecommons.org/licenses/by-sa/2.0/',\n",
       "  'id': 5,\n",
       "  'name': 'Attribution-ShareAlike License'},\n",
       " {'url': 'http://creativecommons.org/licenses/by-nd/2.0/',\n",
       "  'id': 6,\n",
       "  'name': 'Attribution-NoDerivs License'},\n",
       " {'url': 'http://flickr.com/commons/usage/',\n",
       "  'id': 7,\n",
       "  'name': 'No known copyright restrictions'},\n",
       " {'url': 'http://www.usa.gov/copyright.shtml',\n",
       "  'id': 8,\n",
       "  'name': 'United States Government Work'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['licenses'] #4, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inception():\n",
    "    '''\n",
    "    creates inceptionV3 pretrained model without the last layer\n",
    "    \n",
    "    args: None\n",
    "    \n",
    "    returns: model as described above\n",
    "    \n",
    "    '''\n",
    "    model = tf.keras.applications.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "    inp = model.input\n",
    "    out = model.layers[-2].output\n",
    "    mdl = tf.keras.Model(inp, out)\n",
    "    return mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_VGG16():\n",
    "    '''\n",
    "    creates inceptionV3 pretrained model without the last layer\n",
    "    \n",
    "    args: None\n",
    "    \n",
    "    returns: model as described above\n",
    "    \n",
    "    '''\n",
    "    model = tf.keras.applications.VGG16(include_top=True,input_shape=(224,224,3))\n",
    "    inp = model.input\n",
    "    out = model.layers[-2].output\n",
    "    mdl = tf.keras.Model(inp, out)\n",
    "    return mdl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_features(file_name, model, size):\n",
    "    '''\n",
    "    extracts image features from pretrained model\n",
    "    \n",
    "    args:\n",
    "        file_name: str, file name of image\n",
    "        model: tf.keras pretrained model\n",
    "        size: int, pixel size to resize image to \n",
    "        image will be square: eg size=225 will resize image\n",
    "        to 225 * 225\n",
    "    \n",
    "    returns:\n",
    "        output of model after passing image through \n",
    "    \n",
    "    '''\n",
    "    img = open(file_name, 'rb').read()\n",
    "    img = tf.io.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize_with_pad(img, size, size)\n",
    "    img = tf.expand_dims(img, 0)\n",
    "    img = img/127.5 #preprocess to change pixel values to -1 -> 1\n",
    "    img = img - 1\n",
    "    out = model(img)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TFrecord(image_df, caption_ds, \n",
    "                    tokenizer,\n",
    "                    padding, inception, vgg,\n",
    "                    acceptable_license_nums,\n",
    "                    start_pad, end_pad,\n",
    "                    start_idx, end_idx,\n",
    "                    tfr_num, ttl_tfr=20):\n",
    "    '''\n",
    "    creates a TFrecord file\n",
    "    '''\n",
    "    TFrecord_filepath = 'coco2014_{}_of_{}.tfrecord'.format(tfr_num, ttl_tfr)\n",
    "    with tf.io.TFRecordWriter(TFrecord_filepath) as writer:\n",
    "        for caption in range(start_idx, end_idx + 1):\n",
    "            img_id = caption_ds[caption]['image_id']\n",
    "            if image_df[image_df['id'] == img_id]['license'].item() in acceptable_license_nums:\n",
    "                image_file = image_df[image_df['id'] == img_id]['file_name'].item()\n",
    "                image_file = os.path.join('train2014', image_file)\n",
    "                inception_feature = get_image_features(image_file, inception, 299)\n",
    "                vgg_feature = get_image_features(image_file, vgg, 224)\n",
    "                sequence_ = tokenize(caption_ds[caption]['caption'], tokenizer, padding, \n",
    "                                     start_pad, end_pad, 'post')\n",
    "                words = tf.math.count_nonzero(sequence_, dtype=tf.int32)\n",
    "                x_values, y_values = get_xy_values(sequence_[0], padding)\n",
    "                for idx in range(words - 1):\n",
    "                    \n",
    "                \n",
    "                    TFexample = create_TFexample(x_values[idx], inception_feature, \n",
    "                                                 vgg_feature, [y_values[idx]])\n",
    "                    writer.write(TFexample.SerializeToString())\n",
    "    \n",
    "    return TFrecord_filepath\n",
    "                \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_values(sequence_, padding):\n",
    "    '''\n",
    "    create documentation\n",
    "    '''\n",
    "    y_values = sequence_[1:] #tf.reshape(sequence_[1:], (-1, 1)) #not needed\n",
    "\n",
    "\n",
    "    x_values = []\n",
    "    for idx in range(len(sequence_) - 1):\n",
    "        x_value = sequence_[:idx + 1]\n",
    "        x_value = sequence.pad_sequences([x_value], maxlen=padding, padding='post')\n",
    "        x_values.append(x_value)\n",
    "    return x_values, y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_TFexample(x_value, inception_feature, vgg_feature, y_value):\n",
    "    '''\n",
    "    creates a TFexample with the following features:\n",
    "        image\n",
    "        text\n",
    "        ***update documentation***\n",
    "    \n",
    "    args:\n",
    "        dict_: dictionary with the following keys:\n",
    "            id: int, id of image\n",
    "            img: str, file path of image\n",
    "            label: int, indicator if meme is hateful or not\n",
    "            text: str, text on meme\n",
    "        tokenizer: keras.preprocessing.text.Tokenizer object that will be used to preprocess text\n",
    "        padding: int, length of each text vector. If text length is less, zeros will be added to \n",
    "        beginning, and if the text length is greater than padding, it will be truncated\n",
    "        \n",
    "    \n",
    "    returns: TFexample with above features\n",
    "    '''\n",
    "\n",
    "    features = {\n",
    "        'inception': text_feature(inception_feature),\n",
    "        'vgg': text_feature(vgg_feature),\n",
    "        'text': text_feature(x_value),\n",
    "        'y': text_feature(y_value)\n",
    "        \n",
    "    }\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=features))\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(ds_path, client, bucket, annotation_key='annotations', caption_key='caption', max_words=10000, max_len=49,\n",
    "        acceptable_licenses=[4, 7], num_splits=7, oov_token='<unknown>'):\n",
    "    '''\n",
    "    creates TFrecord files, and uploads to GCS bucket\n",
    "    '''\n",
    "    ds = load_jsonl_file(ds_path)[0]\n",
    "    caption_ds = ds[annotation_key]\n",
    "    tokenizer = create_tokenizer(caption_ds, max_words, key=caption_key, oov_token=oov_token)\n",
    "    tokenizer.fit_on_texts('enddd starttt') #words to signal end and beg of sequence\n",
    "    tokenizer.word_counts['enddd'] = 10000\n",
    "    tokenizer.word_counts['starttt'] = 10000\n",
    "    tokenizer.fit_on_texts('enddd starttt')\n",
    "    json_file_name = 'coco_tokenizer.json'\n",
    "    tokenizer_json = tokenizer.to_json()\n",
    "    with open(json_file_name, 'w') as json_file:\n",
    "        json.dump(tokenizer_json, json_file)\n",
    "#     upload_TFrecord_gcs(json_file_name, client, bucket)\n",
    "        \n",
    "    word_idx = json.loads(tokenizer.get_config()['word_index'])\n",
    "    start_idx_token = word_idx['starttt']\n",
    "    end_idx_token = word_idx['enddd']\n",
    "\n",
    "    startEnd_idxs = calc_idxs(caption_ds, num_splits)\n",
    "    image_df = pd.DataFrame.from_records(ds['images'])\n",
    "    inception = create_model_inception()\n",
    "    vgg = create_model_VGG16()\n",
    "    file_num = 1\n",
    "    for startIdx, endIdx in startEnd_idxs:\n",
    "        TFrecord_path = create_TFrecord(image_df, caption_ds, tokenizer,\n",
    "                                        max_len, inception, vgg,\n",
    "                                        acceptable_licenses,\n",
    "                                        start_idx_token, end_idx_token,\n",
    "                                        startIdx, endIdx, \n",
    "                                        file_num, num_splits)\n",
    "#         upload_TFrecord_gcs(TFrecord_path, client, bucket)\n",
    "        file_num +=1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('captions_train2014.json', client, 'jh_coco_2014', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
